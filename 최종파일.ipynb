{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager, rc  # 한글사용 matplotlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import codecs\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import jpype\n",
    "from konlpy.tag import Okt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from pandas import DataFrame as df\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "%matplotlib inline\n",
    "from keras.layers import Dense, Dropout, LSTM, Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "from numpy import newaxis\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, PolynomialFeatures\n",
    "import sklearn.preprocessing as pp\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn.model_selection as ms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'].insert(0, 'Malgun Gothic')\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Input,Dense,GRU, Embedding \n",
    "from tensorflow.python.keras.optimizers import RMSprop,Adam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.python.keras.layers import LSTM, Dropout, Dense, Activation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "print ('module import completed')\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from keras.optimizers import adam\n",
    "\n",
    "def get_eval(y_test, y_pred) :\n",
    "    mae_1 = mae(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse=np.sqrt(mse(y_test, y_pred))\n",
    "    print('mae :',mae_1 )\n",
    "    print('rmse :', rmse)\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as pyplot\n",
    "mpl.rcParams['font.family'].insert(0, 'Malgun Gothic')\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afsnt = pd.read_csv('bigcontest/2019빅콘테스트_퓨처스리그2/AFSNT.csv',engine='python',encoding='cp949')\n",
    "df_afsnt[\"STT\"] = pd.to_datetime(df_afsnt[\"STT\"], format = \"%H:%M\").dt.time\n",
    "df_afsnt[\"ATT\"] = pd.to_datetime(df_afsnt[\"ATT\"], format = \"%H:%M\").dt.time\n",
    "\n",
    "df_afsnt = df_afsnt.rename(columns={ \n",
    "    \"SDT_YY\": \"year\", \"SDT_MM\":\"month\", \"SDT_DD\":\"day\",  \"SDT_DY\":\"wday\", \n",
    "    \"ARP\":\"origin\", \"ODP\":\"dest\", \n",
    "    \"FLO\":\"airline\", \"FLT\":\"flight\" ,\"REG\":\"tailnum\", \n",
    "    \"AOD\":\"is_arrive\", \n",
    "    \"IRR\":\"is_regular\", \n",
    "    \"STT\":\"sched_time\", \"ATT\":\"real_time\", \n",
    "    \"DLY\":\"is_delay\", \"DRR\":\"cause_delay\", \n",
    "    \"CNL\":\"is_cancel\", \"CNR\":\"cause_cancel\"\n",
    "})\n",
    "df_afsnt[\"date\"] = pd.to_datetime(df_afsnt[[\"year\", \"month\", \"day\"]])\n",
    "df_afsnt[\"sched_datetime\"] = pd.to_datetime(df_afsnt['date'].astype(str) + \" \" + df_afsnt[\"sched_time\"].astype(str))\n",
    "df_afsnt[\"real_datetime\"] = pd.to_datetime(df_afsnt['date'].astype(str) + \" \" + df_afsnt[\"real_time\"].astype(str))\n",
    "\n",
    "# delay 변수 생성\n",
    "temp = df_afsnt[\"real_datetime\"] - df_afsnt[\"sched_datetime\"] \n",
    "temp = pd.DataFrame(temp.dt.components)\n",
    "df_afsnt[\"delay\"] = temp['minutes'] + 60 * temp['hours'] + 1440 * temp['days']\n",
    "del temp\n",
    "\n",
    "# 공항 테이블\n",
    "df_afsnt['origin'] = df_afsnt['origin'].replace({\n",
    "    'ARP1': '김포',\n",
    "    'ARP2': '김해',\n",
    "    'ARP3': '제주',\n",
    "    'ARP4': '대구',\n",
    "    'ARP5': '울산',\n",
    "    'ARP6': '청주',\n",
    "    'ARP7': '무안',\n",
    "    'ARP8': '광주',\n",
    "    'ARP9': '여수',\n",
    "    'ARP10': '양양',\n",
    "    'ARP11': '포항',\n",
    "    'ARP12': '사천',\n",
    "    'ARP13': '군산',\n",
    "    'ARP14': '원주',\n",
    "    'ARP15': '인천',    \n",
    "})\n",
    "df_afsnt['dest'] = df_afsnt['dest'].replace({\n",
    "    'ARP1': '김포',\n",
    "    'ARP2': '김해',\n",
    "    'ARP3': '제주',\n",
    "    'ARP4': '대구',\n",
    "    'ARP5': '울산',\n",
    "    'ARP6': '청주',\n",
    "    'ARP7': '무안',\n",
    "    'ARP8': '광주',\n",
    "    'ARP9': '여수',\n",
    "    'ARP10': '양양',\n",
    "    'ARP11': '포항',\n",
    "    'ARP12': '사천',\n",
    "    'ARP13': '군산',\n",
    "    'ARP14': '원주',\n",
    "    'ARP15': '인천',    \n",
    "})\n",
    "\n",
    "# 항공사 테이블 \n",
    "df_afsnt['airline'] = df_afsnt['airline'].replace({\n",
    "    'A': '아시아나', \n",
    "    'I': '진에어',\n",
    "    'J': '대한항공', \n",
    "    'F': '이스타',\n",
    "    'H': '제주항공', \n",
    "    'L': '티웨이',\n",
    "    'B': '에어부산', \n",
    "    'M': '코리아익스프레스에어'\n",
    "})\n",
    "\n",
    "# 결항 데이터 제거\n",
    "# tailnum 널값 제거 4개 정도임 결항 제거하면\n",
    "# ARP1 -> ARP1 으로 가는 이상 데이터 제거\n",
    "\n",
    "df_afsnt = df_afsnt[df_afsnt['is_cancel']=='N']\n",
    "df_afsnt = df_afsnt[~(df_afsnt['tailnum'].isnull())]\n",
    "df_afsnt = df_afsnt[~((df_afsnt['origin']=='김포') & (df_afsnt['dest']=='김포'))]\n",
    "df_afsnt = df_afsnt[(df_afsnt[\"airline\"] != \"C\") & (df_afsnt[\"airline\"] != \"D\") & (df_afsnt[\"airline\"] != \"K\") & (df_afsnt[\"airline\"] != \"G\") & \\\n",
    "         (df_afsnt[\"airline\"] != \"E\")]\n",
    "\n",
    "\n",
    "df_afsnt.index = list(range(len(df_afsnt)))\n",
    "\n",
    "# 시간 범주화 함수 정의\n",
    "def time_dicrete(stt):\n",
    "    time_dic = []\n",
    "    for i in range(len(stt)):\n",
    "        st_base = str(stt[i])\n",
    "        st = int(st_base.split(':')[0])*60 + int(st_base.split(':')[1])\n",
    "        if st >= 300 and st < 480:\n",
    "            time_dic.append('5시-8시')\n",
    "        elif st >= 480 and st < 660:\n",
    "            time_dic.append('8시-11시')\n",
    "        elif st >= 660 and st < 840:\n",
    "            time_dic.append('11시-14시')\n",
    "        elif st >= 840 and st < 1020:\n",
    "            time_dic.append('14시-17시')\n",
    "        elif st >= 1020 and st < 1200:\n",
    "            time_dic.append('17시-20시')\n",
    "        elif st >= 1200 and st < 1380:\n",
    "            time_dic.append('20시-23시')\n",
    "        elif st >=1380 or st<300:\n",
    "            time_dic.append('23시-3시')\n",
    "    return time_dic  \n",
    "\n",
    "stt = list(df_afsnt['sched_time'])\n",
    "\n",
    "a = time_dicrete(stt)\n",
    "df_afsnt['time_discrete'] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 혼잡도 변수 생성\n",
    "# +- 15/30분 기준으로 운행하는 비행기의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +- 30분 기준 혼잡도 변수 생성\n",
    "# 오래걸림\n",
    "\n",
    "# 출도착 구분\n",
    "\n",
    "df_afsnt_d = df_afsnt[df_afsnt['is_arrive']=='D']\n",
    "df_afsnt_a = df_afsnt[df_afsnt['is_arrive']=='A']\n",
    "\n",
    "# 출발기준 혼잡도\n",
    "\n",
    "df_afsnt_d = df_afsnt_d.sort_values(['origin','date','sched_time'])\n",
    "df_afsnt_d.index = list(range(len(df_afsnt_d)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=30)\n",
    "congestion_d = []\n",
    "\n",
    "for i in range(len(df_afsnt_d)):\n",
    "    \n",
    "    airport = df_afsnt_d['origin'][i]\n",
    "    sched_time = df_afsnt_d['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time + base_time\n",
    "    congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(df_afsnt_d)-30) else len(df_afsnt_d) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airport == df_afsnt_d['origin'][j]) and (lower_time <= df_afsnt_d['sched_datetime'][j]) and (df_afsnt_d['sched_datetime'][j] <= upper_time):\n",
    "            congestion_cnt +=1\n",
    "    congestion_d.append(congestion_cnt)\n",
    "    \n",
    "df_afsnt_d['congestion'] = congestion_d\n",
    "\n",
    "# 도착 기준 혼잡도\n",
    "\n",
    "df_afsnt_a = df_afsnt_a.sort_values(['dest','date','sched_time'])\n",
    "df_afsnt_a.index = list(range(len(df_afsnt_a)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=30)\n",
    "congestion_a = []\n",
    "\n",
    "for i in range(len(df_afsnt_a)):\n",
    "    \n",
    "    airport = df_afsnt_a['dest'][i]\n",
    "    sched_time = df_afsnt_a['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time + base_time\n",
    "    congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(df_afsnt_a)-30) else len(df_afsnt_a) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airport == df_afsnt_a['dest'][j]) and (lower_time <= df_afsnt_a['sched_datetime'][j]) and (df_afsnt_a['sched_datetime'][j] <= upper_time):\n",
    "            congestion_cnt +=1\n",
    "    congestion_a.append(congestion_cnt)\n",
    "    \n",
    "df_afsnt_a['congestion'] = congestion_a\n",
    "\n",
    "# +- 15분 간격으로 혼잡도 변수 생성\n",
    "\n",
    "# 출발기준 혼잡도\n",
    "\n",
    "df_afsnt_d = df_afsnt_d.sort_values(['origin','date','sched_time'])\n",
    "df_afsnt_d.index = list(range(len(df_afsnt_d)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=15)\n",
    "congestion_d = []\n",
    "\n",
    "for i in range(len(df_afsnt_d)):\n",
    "    \n",
    "    airport = df_afsnt_d['origin'][i]\n",
    "    sched_time = df_afsnt_d['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time + base_time\n",
    "    congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(df_afsnt_d)-30) else len(df_afsnt_d) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airport == df_afsnt_d['origin'][j]) and (lower_time <= df_afsnt_d['sched_datetime'][j]) and (df_afsnt_d['sched_datetime'][j] <= upper_time):\n",
    "            congestion_cnt +=1\n",
    "    congestion_d.append(congestion_cnt)\n",
    "    \n",
    "df_afsnt_d['congestion_15'] = congestion_d\n",
    "\n",
    "# 도착 기준 혼잡도\n",
    "\n",
    "df_afsnt_a = df_afsnt_a.sort_values(['dest','date','sched_time'])\n",
    "df_afsnt_a.index = list(range(len(df_afsnt_a)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=15)\n",
    "congestion_a = []\n",
    "\n",
    "for i in range(len(df_afsnt_a)):\n",
    "    \n",
    "    airport = df_afsnt_a['dest'][i]\n",
    "    sched_time = df_afsnt_a['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time + base_time\n",
    "    congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(df_afsnt_a)-30) else len(df_afsnt_a) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airport == df_afsnt_a['dest'][j]) and (lower_time <= df_afsnt_a['sched_datetime'][j]) and (df_afsnt_a['sched_datetime'][j] <= upper_time):\n",
    "            congestion_cnt +=1\n",
    "    congestion_a.append(congestion_cnt)\n",
    "    \n",
    "df_afsnt_a['congestion_15'] = congestion_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 링크 및 air_sequence 변수 생성\n",
    "# 링크는 동일 등록기호의 연결성을 파악하기 위한 번호(시간 기준으로 번호)\n",
    "# air_sequence는 공항에서 시간순으로 정렬한 번호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 링크데이터를 위한 정렬\n",
    "\n",
    "df_afsnt_sorted_d = df_afsnt_d.sort_values(['date','tailnum','sched_datetime'])\n",
    "df_afsnt_sorted_a = df_afsnt_a.sort_values(['date','tailnum','sched_datetime'])\n",
    "\n",
    "df_afsnt_sorted_d.index = list(range(len(df_afsnt_sorted_d)))\n",
    "link_ref_d = df_afsnt_sorted_d.pivot_table(index = ['date','tailnum'],aggfunc='count',values='is_arrive' )\n",
    "link_ref_list_d = list(link_ref_d['is_arrive'].values)\n",
    "\n",
    "#linkdata - departure\n",
    "\n",
    "link_d = []\n",
    "\n",
    "for i in link_ref_list_d:\n",
    "    link_range = list(range(i))\n",
    "    link_d.append(link_range)\n",
    "    \n",
    "link_d = sum(link_d, [])\n",
    "df_afsnt_sorted_d['link'] = link_d\n",
    "\n",
    "\n",
    "df_afsnt_sorted_a.index = list(range(len(df_afsnt_sorted_a)))\n",
    "link_ref_a = df_afsnt_sorted_a.pivot_table(index = ['date','tailnum'],aggfunc='count',values='is_arrive' )\n",
    "link_ref_list_a = list(link_ref_a['is_arrive'].values)\n",
    "\n",
    "#linkdata - arrival\n",
    "\n",
    "link_a = []\n",
    "\n",
    "for i in link_ref_list_a:\n",
    "    link_range = list(range(i))\n",
    "    link_a.append(link_range)\n",
    "    \n",
    "link_a = sum(link_a, [])\n",
    "df_afsnt_sorted_a['link'] = link_a\n",
    "\n",
    "df_afsnt = pd.concat([df_afsnt_sorted_d, df_afsnt_sorted_a], sort = False)\n",
    "\n",
    "df_afsnt_d = df_afsnt[df_afsnt['is_arrive']=='D']\n",
    "df_afsnt_a = df_afsnt[df_afsnt['is_arrive']=='A']\n",
    "df_afsnt_d = df_afsnt_d.sort_values(['date','origin','sched_time'])\n",
    "df_afsnt_a = df_afsnt_a.sort_values(['date','dest','sched_time'])\n",
    "\n",
    "df_afsnt_d.index = list(range(len(df_afsnt_d)))\n",
    "df_afsnt_a.index = list(range(len(df_afsnt_a)))\n",
    "\n",
    "air_sequence = []\n",
    "x = 0\n",
    "\n",
    "for i in range(len(df_afsnt_d)):\n",
    "    if i == 0:\n",
    "        air_sequence.append(0)\n",
    "    elif (df_afsnt_d['date'][i] == df_afsnt_d['date'][i-1]) and (df_afsnt_d['origin'][i] == df_afsnt_d['origin'][i-1]):\n",
    "            if df_afsnt_d['sched_datetime'][i] > df_afsnt_d['sched_datetime'][i-1]:\n",
    "                x +=1\n",
    "                air_sequence.append(x)\n",
    "            elif df_afsnt_d['sched_datetime'][i] == df_afsnt_d['sched_datetime'][i-1]:\n",
    "                air_sequence.append(x)\n",
    "            elif df_afsnt_d['sched_datetime'][i] < df_afsnt_d['sched_datetime'][i-1]:\n",
    "                x = 0\n",
    "                air_sequence.append(x)\n",
    "    \n",
    "    else :\n",
    "        x = 0\n",
    "        air_sequence.append(x)\n",
    "\n",
    "df_afsnt_d['air_sequence'] = air_sequence\n",
    "\n",
    "air_sequence = []\n",
    "x = 0\n",
    "\n",
    "for i in range(len(df_afsnt_a)):\n",
    "    if i == 0:\n",
    "        air_sequence.append(0)\n",
    "    elif (df_afsnt_a['date'][i] == df_afsnt_a['date'][i-1]) and (df_afsnt_a['dest'][i] == df_afsnt_a['dest'][i-1]):\n",
    "            if df_afsnt_a['sched_datetime'][i] > df_afsnt_a['sched_datetime'][i-1]:\n",
    "                x +=1\n",
    "                air_sequence.append(x)\n",
    "            elif df_afsnt_a['sched_datetime'][i] == df_afsnt_a['sched_datetime'][i-1]:\n",
    "                air_sequence.append(x)\n",
    "            elif df_afsnt_a['sched_datetime'][i] < df_afsnt_a['sched_datetime'][i-1]:\n",
    "                x = 0\n",
    "                air_sequence.append(x)\n",
    "    \n",
    "    else :\n",
    "        x = 0\n",
    "        air_sequence.append(x)\n",
    "\n",
    "df_afsnt_a['air_sequence'] = air_sequence\n",
    "\n",
    "df_afsnt = pd.concat([df_afsnt_d, df_afsnt_a], sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중심성 분석 결과 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 링크테이블\n",
    "\n",
    "# 출발 링크테이블\n",
    "\n",
    "df_afsnt_d = df_afsnt[df_afsnt['is_arrive']=='D']\n",
    "\n",
    "link_table_d = df_afsnt_d.pivot_table(index=['origin','dest','link'],aggfunc='count',values='is_arrive')\n",
    "link_table_d = link_table_d.reset_index(['origin','dest','link'])\n",
    "link_table_d.columns = ['origin','dest','link','count']\n",
    "\n",
    "# 도착 링크\n",
    "\n",
    "df_afsnt_a = df_afsnt[df_afsnt['is_arrive']=='A']\n",
    "\n",
    "link_table_a = df_afsnt_a.pivot_table(index=['origin','dest','link'],aggfunc='count',values='is_arrive')\n",
    "link_table_a = link_table_a.reset_index(['origin','dest','link'])\n",
    "link_table_a.columns = ['origin','dest','link','count']\n",
    "\n",
    "# 전체 링크\n",
    "\n",
    "link_table =  df_afsnt.pivot_table(index=['origin','dest','link'],aggfunc='count',values='is_arrive')\n",
    "link_table = link_table.reset_index(['origin','dest','link'])\n",
    "link_table.columns = ['origin','dest','link','count']\n",
    "\n",
    "# 테스트셋 테이블 생성\n",
    "# link_table_d.to_csv('bigcontest/test_ref/link_table_d.csv', encoding = 'cp949', index = False)\n",
    "# link_table_a.to_csv('bigcontest/test_ref/link_table_a.csv', encoding = 'cp949', index = False)\n",
    "# link_table.to_csv('bigcontest/test_ref/link_table.csv', encoding = 'cp949', index = False)\n",
    "\n",
    "\n",
    "# 중심성 분석 함수\n",
    "# 가중치 고려\n",
    "\n",
    "def get_degree_centrality(df,arp) :\n",
    "    N = 15\n",
    "    Z = df[df['origin']==arp]['count'].sum()\n",
    "    D = Z/(N-1)\n",
    "    return D\n",
    "\n",
    "\n",
    "# 가중치 고려 x\n",
    "\n",
    "def degree_centrality(df,arp):\n",
    "    N =15\n",
    "    a = df[df['origin']==arp]\n",
    "    D = len((a['origin']+','+a['dest']).unique())/(N-1)\n",
    "    return D\n",
    "\n",
    "# 중심성 분석 \n",
    "\n",
    "arp_list = list(link_table_d['origin'].unique())\n",
    "center_link_d = pd.DataFrame(data=arp_list,columns=['origin'])\n",
    "D_list = []\n",
    "\n",
    "for i in arp_list:\n",
    "    D = get_degree_centrality(link_table_d, i)\n",
    "    D_list.append(D)\n",
    "\n",
    "center_link_d['degree_center_weight'] = D_list\n",
    "\n",
    "# 가중치 고려x\n",
    "\n",
    "N =15\n",
    "arp_list = list(link_table_d['origin'].unique())\n",
    "center_link2_d= pd.DataFrame(data=arp_list,columns=['origin'])\n",
    "D_list = []\n",
    "\n",
    "for i in arp_list:\n",
    "    D = degree_centrality(link_table_d, i)\n",
    "    D_list.append(D)\n",
    "    \n",
    "center_link2_d['degree_center'] = D_list\n",
    "\n",
    "center_link_d_total = pd.merge(center_link_d, center_link2_d)\n",
    "\n",
    "# 원 데이터에 매핑\n",
    "\n",
    "ref_dict = {}\n",
    "\n",
    "for i in range(len(center_link_d_total)):\n",
    "    ref_dict[center_link_d_total['origin'][i]] = center_link_d_total['degree_center_weight'][i]\n",
    "    \n",
    "ref_dict2 = {}\n",
    "for i in range(len(center_link_d_total)):\n",
    "    ref_dict2[center_link_d_total['origin'][i]] = center_link_d_total['degree_center'][i]\n",
    "\n",
    "df_afsnt_d['degree_center_weight_origin'] = df_afsnt_d['origin'].map(ref_dict)\n",
    "df_afsnt_d['degree_center_weight_dest'] = df_afsnt_d['dest'].map(ref_dict)\n",
    "df_afsnt_d['degree_center_origin'] = df_afsnt_d['origin'].map(ref_dict2)\n",
    "df_afsnt_d['degree_center_dest'] = df_afsnt_d['dest'].map(ref_dict2)\n",
    "\n",
    "# 중심성 분석 \n",
    "\n",
    "arp_list = list(link_table_a['origin'].unique())\n",
    "center_link_a = pd.DataFrame(data=arp_list,columns=['origin'])\n",
    "D_list = []\n",
    "\n",
    "for i in arp_list:\n",
    "    D = get_degree_centrality(link_table_a, i)\n",
    "    D_list.append(D)\n",
    "\n",
    "center_link_a['degree_center_weight'] = D_list\n",
    "\n",
    "# 가중치 고려x\n",
    "\n",
    "N =15\n",
    "arp_list = list(link_table_a['origin'].unique())\n",
    "center_link2_a= pd.DataFrame(data=arp_list,columns=['origin'])\n",
    "D_list = []\n",
    "\n",
    "for i in arp_list:\n",
    "    D = degree_centrality(link_table_a, i)\n",
    "    D_list.append(D)\n",
    "    \n",
    "center_link2_a['degree_center'] = D_list\n",
    "center_link_a_total = pd.merge(center_link_a, center_link2_a)\n",
    "\n",
    "# 원데이터에 매핑\n",
    "\n",
    "ref_dict = {}\n",
    "\n",
    "for i in range(len(center_link_a_total)):\n",
    "    ref_dict[center_link_a_total['origin'][i]] = center_link_a_total['degree_center_weight'][i]\n",
    "    \n",
    "ref_dict2 = {}\n",
    "for i in range(len(center_link_a_total)):\n",
    "    ref_dict2[center_link_a_total['origin'][i]] = center_link_a_total['degree_center'][i]\n",
    "\n",
    "df_afsnt_a['degree_center_weight_origin'] = df_afsnt_a['origin'].map(ref_dict)\n",
    "df_afsnt_a['degree_center_weight_dest'] = df_afsnt_a['dest'].map(ref_dict)\n",
    "df_afsnt_a['degree_center_origin'] = df_afsnt_a['origin'].map(ref_dict2)\n",
    "df_afsnt_a['degree_center_dest'] = df_afsnt_a['dest'].map(ref_dict2)\n",
    "\n",
    "df_afsnt = pd.concat([df_afsnt_d,df_afsnt_a], sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 항공 흐름 혼잡도 변수 생성\n",
    "# 같은 노선에 혼잡정도를 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 항공흐름 혼잡도 / 출도착 구분 \n",
    "# 오래걸림\n",
    "\n",
    "df_afsnt['origin_dest'] = df_afsnt['origin']+','+df_afsnt['dest']\n",
    "# 15분 전 항공흐름\n",
    "\n",
    "# 출도착 구분\n",
    "\n",
    "df_afsnt_d = df_afsnt[df_afsnt['is_arrive']=='D']\n",
    "df_afsnt_a = df_afsnt[df_afsnt['is_arrive']=='A']\n",
    "\n",
    "df_afsnt_d = df_afsnt_d.sort_values(['date','origin_dest','sched_time'])\n",
    "df_afsnt_a = df_afsnt_a.sort_values(['date','origin_dest','sched_time'])\n",
    "\n",
    "df_afsnt_d.index = list(range(len(df_afsnt_d)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=15)\n",
    "air_congestion_d = []\n",
    "\n",
    "for i in range(len(df_afsnt_d)):\n",
    "    \n",
    "    airway = df_afsnt_d['origin_dest'][i]\n",
    "    sched_time = df_afsnt_d['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time \n",
    "    air_congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(df_afsnt_d)-30) else len(df_afsnt_d) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airway == df_afsnt_d['origin_dest'][j]) and (lower_time <= df_afsnt_d['sched_datetime'][j]) and (df_afsnt_d['sched_datetime'][j] <= upper_time):\n",
    "            air_congestion_cnt +=1\n",
    "    air_congestion_d.append(air_congestion_cnt)\n",
    "    \n",
    "df_afsnt_d['air_congestion_15'] = air_congestion_d\n",
    "\n",
    "\n",
    "df_afsnt_a.index = list(range(len(df_afsnt_a)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=15)\n",
    "air_congestion_a = []\n",
    "\n",
    "for i in range(len(df_afsnt_a)):\n",
    "    \n",
    "    airway = df_afsnt_a['origin_dest'][i]\n",
    "    sched_time = df_afsnt_a['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time \n",
    "    air_congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(df_afsnt_a)-30) else len(df_afsnt_a) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airway == df_afsnt_a['origin_dest'][j]) and (lower_time <= df_afsnt_a['sched_datetime'][j]) and (df_afsnt_a['sched_datetime'][j] <= upper_time):\n",
    "            air_congestion_cnt +=1\n",
    "    air_congestion_a.append(air_congestion_cnt)\n",
    "    \n",
    "df_afsnt_a['air_congestion_15'] = air_congestion_a\n",
    "\n",
    "df_afsnt = pd.concat([df_afsnt_d, df_afsnt_a], sort= False)\n",
    "\n",
    "# 항공흐름 혼잡도 / 출도착 구분 \n",
    "# 30분 전 항공흐름\n",
    "\n",
    "# 출도착 구분\n",
    "\n",
    "df_afsnt_d = df_afsnt[df_afsnt['is_arrive']=='D']\n",
    "df_afsnt_a = df_afsnt[df_afsnt['is_arrive']=='A']\n",
    "\n",
    "df_afsnt_d = df_afsnt_d.sort_values(['date','origin_dest','sched_time'])\n",
    "df_afsnt_a = df_afsnt_a.sort_values(['date','origin_dest','sched_time'])\n",
    "\n",
    "df_afsnt_d.index = list(range(len(df_afsnt_d)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=30)\n",
    "air_congestion_d = []\n",
    "\n",
    "for i in range(len(df_afsnt_d)):\n",
    "    \n",
    "    airway = df_afsnt_d['origin_dest'][i]\n",
    "    sched_time = df_afsnt_d['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time \n",
    "    air_congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(df_afsnt_d)-30) else len(df_afsnt_d) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airway == df_afsnt_d['origin_dest'][j]) and (lower_time <= df_afsnt_d['sched_datetime'][j]) and (df_afsnt_d['sched_datetime'][j] <= upper_time):\n",
    "            air_congestion_cnt +=1\n",
    "    air_congestion_d.append(air_congestion_cnt)\n",
    "    \n",
    "df_afsnt_d['air_congestion_30'] = air_congestion_d\n",
    "\n",
    "\n",
    "df_afsnt_a.index = list(range(len(df_afsnt_a)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=30)\n",
    "air_congestion_a = []\n",
    "\n",
    "for i in range(len(df_afsnt_a)):\n",
    "    \n",
    "    airway = df_afsnt_a['origin_dest'][i]\n",
    "    sched_time = df_afsnt_a['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time \n",
    "    air_congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(df_afsnt_a)-30) else len(df_afsnt_a) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airway == df_afsnt_a['origin_dest'][j]) and (lower_time <= df_afsnt_a['sched_datetime'][j]) and (df_afsnt_a['sched_datetime'][j] <= upper_time):\n",
    "            air_congestion_cnt +=1\n",
    "    air_congestion_a.append(air_congestion_cnt)\n",
    "    \n",
    "df_afsnt_a['air_congestion_30'] = air_congestion_a\n",
    "\n",
    "df_afsnt = pd.concat([df_afsnt_d, df_afsnt_a], sort= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 항공사별 비행기의 평균 연결정도 변수 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 항공사의 일별 연결정도 변수\n",
    "\n",
    "df_afsnt_d = df_afsnt[df_afsnt['is_arrive']=='D']\n",
    "df_afsnt_a = df_afsnt[df_afsnt['is_arrive']=='A']\n",
    "\n",
    "# 출도착 일별 평균 비행기 개수\n",
    "\n",
    "d = df_afsnt_d.pivot_table(index = ['date', 'airline','tailnum'], aggfunc = 'count', values = 'is_arrive')\n",
    "d = d.reset_index(['date','airline','tailnum'])\n",
    "d2 = d.pivot_table(index = ['date','airline'], aggfunc = 'count', values = 'tailnum')\n",
    "d2 = d2.reset_index(['date','airline'])\n",
    "dd =d2.pivot_table(index = 'airline', aggfunc = 'mean', values = 'tailnum')\n",
    "dd = dd.reset_index(['airline'])\n",
    "dd.columns = ['airline','count']\n",
    "\n",
    "a = df_afsnt_a.pivot_table(index = ['date', 'airline','tailnum'], aggfunc = 'count', values = 'is_arrive')\n",
    "a = a.reset_index(['date','airline','tailnum'])\n",
    "a2 = a.pivot_table(index = ['date','airline'], aggfunc = 'count', values = 'tailnum')\n",
    "a2 = a2.reset_index(['date','airline'])\n",
    "aa =a2.pivot_table(index = 'airline', aggfunc = 'mean', values = 'tailnum')\n",
    "aa = aa.reset_index(['airline'])\n",
    "aa.columns = ['airline','count']\n",
    "\n",
    "# 테스트셋 테이블\n",
    "# dd.to_csv('bigcontest/test_ref/dd.csv', index = False, encoding = 'cp949')\n",
    "# aa.to_csv('bigcontest/test_ref/aa.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "x = df_afsnt_d.pivot_table(index = ['date','airline'],aggfunc = 'count', values = 'is_arrive')\n",
    "x = x.reset_index(['date','airline'])\n",
    "x.columns = ['date','airline','count']\n",
    "\n",
    "y = df_afsnt_a.pivot_table(index = ['date','airline'],aggfunc = 'count', values = 'is_arrive')\n",
    "y = y.reset_index(['date','airline'])\n",
    "y.columns = ['date','airline','count']\n",
    "\n",
    "link_count = []\n",
    "for i in range(len(x)):\n",
    "    a = x['count'][i]\n",
    "    b = float(dd[dd['airline']==x['airline'][i]]['count'].values)\n",
    "    cnt = a/b\n",
    "    link_count.append(cnt)\n",
    "x['link_count'] = link_count\n",
    "\n",
    "link_count = []\n",
    "for i in range(len(y)):\n",
    "    a = y['count'][i]\n",
    "    b = float(aa[aa['airline']==y['airline'][i]]['count'].values)\n",
    "    cnt = a/b\n",
    "    link_count.append(cnt)\n",
    "y['link_count'] = link_count\n",
    "\n",
    "x = x.drop(columns = 'count')\n",
    "y = y.drop(columns = 'count')\n",
    "\n",
    "df_afsnt_d = pd.merge(df_afsnt_d,x, on = ['date','airline'])\n",
    "df_afsnt_a = pd.merge(df_afsnt_a, y, on = ['date','airline'])\n",
    "\n",
    "df_afsnt = pd.concat([df_afsnt_d, df_afsnt_a], sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 항공사별 시간순 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 항공사별 sequence 생성\n",
    "\n",
    "df_afsnt_d = df_afsnt[df_afsnt['is_arrive']=='D']\n",
    "df_afsnt_a = df_afsnt[df_afsnt['is_arrive']=='A']\n",
    "\n",
    "df_afsnt_d = df_afsnt_d.sort_values(['date','airline','sched_time'])\n",
    "df_afsnt_a = df_afsnt_a.sort_values(['date','airline','sched_time'])\n",
    "\n",
    "df_afsnt_d.index = list(range(len(df_afsnt_d)))\n",
    "df_afsnt_a.index = list(range(len(df_afsnt_a)))\n",
    "\n",
    "# 출발\n",
    "\n",
    "air_link = []\n",
    "x = 0\n",
    "\n",
    "for i in range(len(df_afsnt_d)):\n",
    "    if i == 0:\n",
    "        air_link.append(0)\n",
    "    \n",
    "    elif df_afsnt_d['sched_datetime'][i] > df_afsnt_d['sched_datetime'][i-1]:\n",
    "        if df_afsnt_d['day'][i] == df_afsnt_d['day'][i-1]:\n",
    "            x += 1\n",
    "            air_link.append(x)\n",
    "        elif df_afsnt_d['day'][i] > df_afsnt_d['day'][i-1]:\n",
    "            x = 0\n",
    "            air_link.append(x)\n",
    "        elif df_afsnt_d['day'][i] < df_afsnt_d['day'][i-1]:\n",
    "            x = 0\n",
    "            air_link.append(x)\n",
    "        \n",
    "    elif df_afsnt_d['sched_datetime'][i] == df_afsnt_d['sched_datetime'][i-1]:\n",
    "        air_link.append(x)\n",
    "        \n",
    "    elif df_afsnt_d['sched_datetime'][i] < df_afsnt_d['sched_datetime'][i-1]:\n",
    "        x = 0\n",
    "        air_link.append(x)\n",
    "\n",
    "df_afsnt_d['air_link'] = air_link\n",
    "\n",
    "# 도착\n",
    "\n",
    "air_link = []\n",
    "x = 0\n",
    "\n",
    "for i in range(len(df_afsnt_a)):\n",
    "    if i == 0:\n",
    "        air_link.append(0)\n",
    "    \n",
    "    elif df_afsnt_a['sched_datetime'][i] > df_afsnt_a['sched_datetime'][i-1]:\n",
    "        if df_afsnt_a['day'][i] == df_afsnt_a['day'][i-1]:\n",
    "            x += 1\n",
    "            air_link.append(x)\n",
    "        elif df_afsnt_a['day'][i] > df_afsnt_a['day'][i-1]:\n",
    "            x = 0\n",
    "            air_link.append(x)\n",
    "        elif df_afsnt_a['day'][i] < df_afsnt_a['day'][i-1]:\n",
    "            x = 0\n",
    "            air_link.append(x)\n",
    "        \n",
    "    elif df_afsnt_a['sched_datetime'][i] == df_afsnt_a['sched_datetime'][i-1]:\n",
    "        air_link.append(x)\n",
    "        \n",
    "    elif df_afsnt_a['sched_datetime'][i] < df_afsnt_a['sched_datetime'][i-1]:\n",
    "        x = 0\n",
    "        air_link.append(x)\n",
    "        \n",
    "\n",
    "df_afsnt_a['air_link'] = air_link\n",
    "\n",
    "\n",
    "# 공항별 항공사별 sequence 생성\n",
    "\n",
    "df_afsnt_d = df_afsnt_d.sort_values(['date','origin','airline','sched_time'])\n",
    "df_afsnt_a = df_afsnt_a.sort_values(['date','dest','airline','sched_time'])\n",
    "\n",
    "df_afsnt_d.index = list(range(len(df_afsnt_d)))\n",
    "df_afsnt_a.index = list(range(len(df_afsnt_a)))\n",
    "\n",
    "air_place_link = []\n",
    "x = 0\n",
    "\n",
    "for i in range(len(df_afsnt_d)):\n",
    "    if i == 0:\n",
    "        air_place_link.append(0)\n",
    "    \n",
    "    elif (df_afsnt_d['origin'][i] == df_afsnt_d['origin'][i-1]) and (df_afsnt_d['date'][i] == df_afsnt_d['date'][i-1]) and (df_afsnt_d['airline'][i] == df_afsnt_d['airline'][i-1]):\n",
    "        if df_afsnt_d['sched_datetime'][i] > df_afsnt_d['sched_datetime'][i-1]:\n",
    "            x += 1\n",
    "            air_place_link.append(x)\n",
    "        elif df_afsnt_d['sched_datetime'][i] == df_afsnt_d['sched_datetime'][i-1]:\n",
    "            air_place_link.append(x)\n",
    "        elif df_afsnt_d['sched_datetime'][i] < df_afsnt_d['sched_datetime'][i-1]:\n",
    "            x = 0\n",
    "            air__placelink.append(x)\n",
    "        \n",
    "    else :\n",
    "        x = 0\n",
    "        air_place_link.append(x)\n",
    "\n",
    "df_afsnt_d['air_place_link'] = air_place_link\n",
    "\n",
    "air_place_link = []\n",
    "x = 0\n",
    "\n",
    "for i in range(len(df_afsnt_a)):\n",
    "    if i == 0:\n",
    "        air_place_link.append(0)\n",
    "    \n",
    "    elif (df_afsnt_a['dest'][i] == df_afsnt_a['dest'][i-1]) and (df_afsnt_a['date'][i] == df_afsnt_a['date'][i-1]) and (df_afsnt_a['airline'][i] == df_afsnt_a['airline'][i-1]):\n",
    "        if df_afsnt_a['sched_datetime'][i] > df_afsnt_a['sched_datetime'][i-1]:\n",
    "            x += 1\n",
    "            air_place_link.append(x)\n",
    "        elif df_afsnt_a['sched_datetime'][i] == df_afsnt_a['sched_datetime'][i-1]:\n",
    "            air_place_link.append(x)\n",
    "        elif df_afsnt_a['sched_datetime'][i] < df_afsnt_a['sched_datetime'][i-1]:\n",
    "            x = 0\n",
    "            air__placelink.append(x)\n",
    "        \n",
    "    else :\n",
    "        x = 0\n",
    "        air_place_link.append(x)\n",
    "\n",
    "df_afsnt_a['air_place_link'] = air_place_link\n",
    "\n",
    "df_afsnt = pd.concat([df_afsnt_d, df_afsnt_a], sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 거리, 공항 관련 데이터(부지면적, 활주로 등), 거리중심성 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거리 매핑 및 거리중심성 \n",
    "\n",
    "distance = pd.read_csv('bigcontest/airport_distance.csv', engine = 'python', encoding = 'cp949')\n",
    "distance['origin_dest'] = distance['origin']+','+distance['dest']\n",
    "df_afsnt['origin_dest'] = df_afsnt['origin']+','+df_afsnt['dest']\n",
    "\n",
    "ref_dict = {}\n",
    "\n",
    "for i in range(len(distance)):\n",
    "    ref_dict[distance['origin_dest'][i]] = distance['distance_km'][i]\n",
    "\n",
    "df_afsnt['distance_km'] = df_afsnt['origin_dest'].map(ref_dict)\n",
    "\n",
    "G = nx.from_pandas_edgelist(df_afsnt, source = \"origin\", target= \"dest\")\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "node, BC = zip(*closeness_centrality.items())\n",
    "center = pd.DataFrame({'origin':node, 'distance_center':BC}).sort_values(by='distance_center',ascending=False)\n",
    "\n",
    "# 테스트셋 테이블 생성\n",
    "# center.to_csv('bigcontest/test_ref/center.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# 매핑\n",
    "\n",
    "ref_dict = {}\n",
    "\n",
    "for i in range(len(center)):\n",
    "    ref_dict[center['origin'][i]] = center['distance_center'][i]\n",
    "\n",
    "df_afsnt['distance_center'] = df_afsnt['origin'].map(ref_dict)\n",
    "\n",
    "# 거리중심성 분석\n",
    "# 어떤 테이블이 있을건데 이것은 출발 - 도착 - 거리를 보여주는 데이터프레임 = df_distance \n",
    "\n",
    "origin_unique = (df_afsnt['origin']).unique()\n",
    "\n",
    "def get_distance_centrality(origin):\n",
    "    N = 15\n",
    "    df_distance = distance[distance['origin']==origin]\n",
    "    df_distance.index = list(range(len(df_distance)))\n",
    "    distance_sum = 0\n",
    "    for i in range(len(df_distance)):\n",
    "        distance_sum += df_distance['distance_km'][i]\n",
    "            \n",
    "    distance_sum_inverse = (distance_sum)**(-1)\n",
    "    distance_center = (N-1)*distance_sum_inverse\n",
    "    return distance_center \n",
    "\n",
    "# 중심성 분석 \n",
    "\n",
    "origin_unique = (df_afsnt['origin']).unique()\n",
    "center_distance = pd.DataFrame(data=origin_unique,columns=['origin'])\n",
    "D_list = []\n",
    "\n",
    "for i in origin_unique:\n",
    "    D = get_distance_centrality(i)\n",
    "    D_list.append(D)\n",
    "\n",
    "center_distance['distance_center'] = D_list\n",
    "\n",
    "ref_dict = {}\n",
    "\n",
    "for i in range(len(center_distance)):\n",
    "    ref_dict[center_distance['origin'][i]] = center_distance['distance_center'][i]\n",
    "\n",
    "df_afsnt['distance_center_weight'] = df_afsnt['origin'].map(ref_dict)\n",
    "\n",
    "# 공항정보 매핑\n",
    "\n",
    "info = pd.read_csv('bigcontest/공항활주로_부지면적.csv', engine='python',encoding='cp949')\n",
    "df_afsnt = pd.merge(df_afsnt, info, on=['origin','year'])\n",
    "df_afsnt = df_afsnt.drop(columns = ['origin_dest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하루당 동일 비행기의 운행횟수 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하루당 해당 비행기 운행횟수\n",
    "\n",
    "df_afsnt_d = df_afsnt[df_afsnt['is_arrive']=='D']\n",
    "df_afsnt_a = df_afsnt[df_afsnt['is_arrive']=='A']\n",
    "\n",
    "d_table = df_afsnt_d.pivot_table(index=['date','tailnum'],aggfunc='count',values='is_arrive')\n",
    "d_table = d_table.reset_index(['date','tailnum'])\n",
    "d_table.columns = ['date','tailnum','cnt_per_day']\n",
    "\n",
    "a_table = df_afsnt_a.pivot_table(index=['date','tailnum'],aggfunc='count',values='is_arrive')\n",
    "a_table = a_table.reset_index(['date','tailnum'])\n",
    "a_table.columns = ['date','tailnum','cnt_per_day']\n",
    "\n",
    "df_afsnt_d2 = pd.merge(df_afsnt_d, d_table, on = ['date','tailnum'])\n",
    "df_afsnt_a2 = pd.merge(df_afsnt_a, a_table, on = ['date','tailnum'])\n",
    "\n",
    "df_afsnt = pd.concat([df_afsnt_d2,df_afsnt_a2], sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 공항 관련 데이터, 시간 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afsnt['is_flight_T'] = np.where(df_afsnt['flight'].str.endswith(\"T\"), 1, 0)\n",
    "df_afsnt['is_flight_M'] = np.where(df_afsnt['flight'].str.endswith(\"M\"), 1, 0)\n",
    "df_afsnt['is_flight_F'] = np.where(df_afsnt['flight'].str.endswith(\"F\"), 1, 0)\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "df_afsnt['sched_datetime'] = pd.to_datetime(df_afsnt['sched_datetime'])\n",
    "\n",
    "# 월\n",
    "df_afsnt['month_sin'] = np.sin(2*df_afsnt['sched_datetime'].dt.month*np.pi / 12 )\n",
    "df_afsnt['month_cos'] = np.cos(2*df_afsnt['sched_datetime'].dt.month*np.pi / 12 )\n",
    "\n",
    "# 요일\n",
    "df_afsnt['sched_datetime'] = pd.to_datetime(df_afsnt['sched_datetime'])\n",
    "df_afsnt['is_weekend'] = np.where((df_afsnt['sched_datetime'].dt.weekday == 6) | (df_afsnt['sched_datetime'].dt.weekday == 5), True, False)\n",
    "\n",
    "# 시간\n",
    "df_afsnt['time_sin'] = 60 * np.sin(2*np.pi*df_afsnt['sched_datetime'].dt.hour / 24) + \\\n",
    "                        np.sin(2*df_afsnt['sched_datetime'].dt.minute*np.pi / 60)\n",
    "df_afsnt['time_cos'] = 60 * np.cos(2*df_afsnt['sched_datetime'].dt.hour*np.pi / 24) + \\\n",
    "                        np.cos(2*np.pi*df_afsnt['sched_datetime'].dt.minute / 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 해발 고도\n",
    "df_altitude = pd.DataFrame(pd.Series({\n",
    "    '김포': 18,\n",
    "    '김해': 4,\n",
    "    '제주': 36,\n",
    "    '대구': 35.4,\n",
    "    '울산': 12.9,\n",
    "    '청주': 58,\n",
    "    '양양': 73.5,\n",
    "    '무안': 23.7,\n",
    "    '광주': 12.8,\n",
    "    '여수': 20,\n",
    "    '사천': 7.6,\n",
    "    '포항': 21.3,\n",
    "    '군산': 8.8,\n",
    "    '원주': 100,\n",
    "    '인천': 7\n",
    "})).reset_index().rename(columns = {'index': 'airport', 0: 'alt'})\n",
    "\n",
    "df_afsnt = pd.merge(df_afsnt, df_altitude, how = \"left\", left_on = 'origin', right_on = 'airport', suffixes = ('_origin', '_dest'))\n",
    "df_afsnt = pd.merge(df_afsnt, df_altitude, how = \"left\", left_on = 'dest', right_on = 'airport', suffixes = ('_origin', '_dest'))\n",
    "df_afsnt.drop(['airport_origin', 'airport_dest'], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# is_변수 True False로 변환\n",
    "df_afsnt[\"is_arrive\"] = np.where(df_afsnt[\"is_arrive\"] == \"A\", True, False)\n",
    "df_afsnt[\"is_regular\"] = np.where(df_afsnt[\"is_regular\"] == \"Y\", True, False)\n",
    "df_afsnt[\"is_delay\"] = np.where(df_afsnt[\"is_delay\"] == \"Y\", True, False)\n",
    "\n",
    "# 추가 변수들\n",
    "df_afsnt['origin_dest'] = df_afsnt['origin'] + '_' + df_afsnt['dest']\n",
    "\n",
    "\n",
    "\n",
    "# 황금연휴 추가\n",
    "\n",
    "df_afsnt['is_goldentime'] = df_afsnt['date'].isin([\"2017-01-26\", \"2017-01-27\", \"2017-01-28\", \"2017-01-29\", \"2017-01-30\", \"2017-01-31\", \"2017-05-05\", \"2017-05-06\", \"2017-05-07\", \"2017-08-15\",\n",
    " \"2017-09-29\", \"2017-09-30\", \"2017-10-01\", \"2017-10-02\", \"2017-10-03\", \"2017-10-04\", \"2017-10-05\", \"2017-10-06\", \"2017-10-07\", \"2017-10-08\", \"2017-10-09\", \"2017-10-10\", \n",
    "                                                   \"2017-12-25\", \"2018-01-01\", \"2018-02-14\", \"2018-02-15\", \"2018-02-16\", \"2018-02-17\", \"2018-02-18\", \"2018-02-19\", \"2018-03-01\",\n",
    " \"2018-05-05\", \"2018-05-07\", \"2018-05-22\",\n",
    " \"2018-06-06\", \"2018-06-13\", \"2018-08-15\", \"2018-09-21\", \"2018-09-22\", \"2018-09-23\", \"2018-09-24\", \"2018-09-25\", \"2018-09-26\", \"2018-09-27\", \n",
    " \"2018-10-03\", \"2018-10-09\", \"2018-12-25\", \n",
    " \"2019-01-01\", \"2019-02-01\", \"2019-02-02\", \"2019-02-03\", \"2019-02-04\", \"2019-02-05\", \"2019-02-06\", \"2019-02-07\",\n",
    " \"2019-03-01\", \"2019-05-04\", \"2019-05-05\", \"2019-05-06\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전비행기와의 시간차 및 거리대비 시간차 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연결 비행기에 있어서 전 비행기와의 시간차이 및 거리를 고려한 시간차이 \n",
    "\n",
    "\n",
    "df_afsnt_d = df_afsnt[df_afsnt['is_arrive']==False]\n",
    "df_afsnt_a = df_afsnt[df_afsnt['is_arrive']==True]\n",
    "\n",
    "# 출발인경우\n",
    "\n",
    "df_afsnt_d_sorted = df_afsnt_d.sort_values(['date','tailnum','sched_time'])\n",
    "df_afsnt_d_sorted.index = list(range(len(df_afsnt_d_sorted)))\n",
    "\n",
    "time_diff = []\n",
    "time_diff_distance = []\n",
    "\n",
    "for i in range(len(df_afsnt_d_sorted)):\n",
    "    if df_afsnt_d_sorted['link'][i] == 0 :\n",
    "        time_diff.append(0)\n",
    "        time_diff_distance.append(0)\n",
    "        \n",
    "    elif df_afsnt_d_sorted['tailnum'][i] != df_afsnt_d_sorted['tailnum'][i-1]:\n",
    "        time_diff.append(0)\n",
    "        time_diff_distance.append(0)\n",
    "        \n",
    "    else :\n",
    "        time_diff_sec = (df_afsnt_d_sorted['sched_datetime'][i] - df_afsnt_d_sorted['sched_datetime'][i-1]).seconds\n",
    "        time_diff_min = int(time_diff_sec/60)\n",
    "        time_diff.append(time_diff_min)\n",
    "        \n",
    "        time_diff_dis = time_diff_min/df_afsnt_d_sorted['distance_km'][i-1]\n",
    "        time_diff_distance.append(time_diff_dis)\n",
    "        \n",
    "df_afsnt_d_sorted['time_diff'] = time_diff\n",
    "df_afsnt_d_sorted['time_diff_distance'] = time_diff_distance\n",
    "\n",
    "# 도착인경우\n",
    "\n",
    "df_afsnt_a_sorted = df_afsnt_a.sort_values(['date','tailnum','sched_time'])\n",
    "df_afsnt_a_sorted.index = list(range(len(df_afsnt_a_sorted)))\n",
    "\n",
    "time_diff = []\n",
    "time_diff_distance = []\n",
    "\n",
    "for i in range(len(df_afsnt_a_sorted)):\n",
    "    if df_afsnt_a_sorted['link'][i] == 0 :\n",
    "        time_diff.append(0)\n",
    "        time_diff_distance.append(0)\n",
    "        \n",
    "    elif df_afsnt_a_sorted['tailnum'][i] != df_afsnt_a_sorted['tailnum'][i-1]:\n",
    "        time_diff.append(0)\n",
    "        time_diff_distance.append(0)\n",
    "        \n",
    "    else :\n",
    "        time_diff_sec = (df_afsnt_a_sorted['sched_datetime'][i] - df_afsnt_a_sorted['sched_datetime'][i-1]).seconds\n",
    "        time_diff_min = int(time_diff_sec/60)\n",
    "        time_diff.append(time_diff_min)\n",
    "        \n",
    "        time_diff_dis = time_diff_min/df_afsnt_a_sorted['distance_km'][i-1]\n",
    "        time_diff_distance.append(time_diff_dis)\n",
    "        \n",
    "df_afsnt_a_sorted['time_diff'] = time_diff\n",
    "df_afsnt_a_sorted['time_diff_distance'] = time_diff_distance\n",
    "df_afsnt = pd.concat([df_afsnt_d_sorted, df_afsnt_a_sorted], sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 항공편 지연비율 매핑 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afsnt_d = df_afsnt[df_afsnt['is_arrive']==False]\n",
    "df_afsnt_a = df_afsnt[df_afsnt['is_arrive']==True]\n",
    "\n",
    "d_x = df_afsnt_d[df_afsnt_d['is_delay']==True].pivot_table(index = 'flight', aggfunc = 'count', values ='is_arrive')\n",
    "d_y = df_afsnt_d.pivot_table(index = 'flight', aggfunc = 'count', values ='is_arrive')\n",
    "a_x = df_afsnt_a[df_afsnt_a['is_delay']==True].pivot_table(index = 'flight', aggfunc = 'count', values ='is_arrive')\n",
    "a_y = df_afsnt_a.pivot_table(index = 'flight', aggfunc = 'count', values ='is_arrive')\n",
    "\n",
    "d = d_x/d_y\n",
    "d = d.reset_index('flight')\n",
    "d.columns  = ['flight','dly_por']\n",
    "a = a_x/a_y\n",
    "a = a.reset_index('flight')\n",
    "a.columns = ['flight','dly_por']\n",
    "\n",
    "d.fillna(d['dly_por'].mean(),inplace=True)\n",
    "a.fillna(a['dly_por'].mean(),inplace=True)\n",
    "\n",
    "df_afsnt_d = pd.merge(df_afsnt_d, d, on = 'flight')\n",
    "df_afsnt_a = pd.merge(df_afsnt_a, a, on = 'flight')\n",
    "df_afsnt = pd.concat([df_afsnt_d, df_afsnt_a], sort=False)\n",
    "\n",
    "# 테스트셋에서의 활용을 위한 테이블\n",
    "# d.to_csv('bigcontest/test_ref/flight_dly_d.csv', index = False, encoding = 'cp949')\n",
    "# a.to_csv('bigcontest/test_ref/flight_dly_a.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "df_afsnt.to_csv('bigcontest/df_afsnt_total_ver10.csv', index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트셋 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('bigcontest/2019빅콘테스트_퓨처스리그2/AFSNT_DLY.csv',engine='python',encoding='cp949')\n",
    "test[\"STT\"] = pd.to_datetime(test[\"STT\"], format = \"%H:%M\").dt.time\n",
    "\n",
    "test = test.rename(columns={ \n",
    "    \"SDT_YY\": \"year\", \"SDT_MM\":\"month\", \"SDT_DD\":\"day\",  \"SDT_DY\":\"wday\", \n",
    "    \"ARP\":\"origin\", \"ODP\":\"dest\", \n",
    "    \"FLO\":\"airline\", \"FLT\":\"flight\" , \n",
    "    \"AOD\":\"is_arrive\",  \n",
    "    \"STT\":\"sched_time\",\n",
    "    \"DLY\":\"is_delay\", \n",
    "})\n",
    "test[\"date\"] = pd.to_datetime(test[[\"year\", \"month\", \"day\"]])\n",
    "test[\"sched_datetime\"] = pd.to_datetime(test['date'].astype(str) + \" \" + test[\"sched_time\"].astype(str))\n",
    "\n",
    "\n",
    "# 공항 테이블\n",
    "test['origin'] = test['origin'].replace({\n",
    "    'ARP1': '김포',\n",
    "    'ARP2': '김해',\n",
    "    'ARP3': '제주',\n",
    "    'ARP4': '대구',\n",
    "    'ARP5': '울산',\n",
    "    'ARP6': '청주',\n",
    "    'ARP7': '무안',\n",
    "    'ARP8': '광주',\n",
    "    'ARP9': '여수',\n",
    "    'ARP10': '양양',\n",
    "    'ARP11': '포항',\n",
    "    'ARP12': '사천',\n",
    "    'ARP13': '군산',\n",
    "    'ARP14': '원주',\n",
    "    'ARP15': '인천',    \n",
    "})\n",
    "test['dest'] = test['dest'].replace({\n",
    "    'ARP1': '김포',\n",
    "    'ARP2': '김해',\n",
    "    'ARP3': '제주',\n",
    "    'ARP4': '대구',\n",
    "    'ARP5': '울산',\n",
    "    'ARP6': '청주',\n",
    "    'ARP7': '무안',\n",
    "    'ARP8': '광주',\n",
    "    'ARP9': '여수',\n",
    "    'ARP10': '양양',\n",
    "    'ARP11': '포항',\n",
    "    'ARP12': '사천',\n",
    "    'ARP13': '군산',\n",
    "    'ARP14': '원주',\n",
    "    'ARP15': '인천',    \n",
    "})\n",
    "\n",
    "# 항공사 테이블 \n",
    "test['airline'] = test['airline'].replace({\n",
    "    'A': '아시아나', \n",
    "    'I': '진에어',\n",
    "    'J': '대한항공', \n",
    "    'F': '이스타',\n",
    "    'H': '제주항공', \n",
    "    'L': '티웨이',\n",
    "    'B': '에어부산', \n",
    "    'M': '코리아익스프레스에어'\n",
    "})\n",
    "\n",
    "\n",
    "test.index = list(range(len(test)))\n",
    "\n",
    "# 시간 범주화 함수 정의\n",
    "def time_dicrete(stt):\n",
    "    time_dic = []\n",
    "    for i in range(len(stt)):\n",
    "        st_base = str(stt[i])\n",
    "        st = int(st_base.split(':')[0])*60 + int(st_base.split(':')[1])\n",
    "        if st >= 300 and st < 480:\n",
    "            time_dic.append('5시-8시')\n",
    "        elif st >= 480 and st < 660:\n",
    "            time_dic.append('8시-11시')\n",
    "        elif st >= 660 and st < 840:\n",
    "            time_dic.append('11시-14시')\n",
    "        elif st >= 840 and st < 1020:\n",
    "            time_dic.append('14시-17시')\n",
    "        elif st >= 1020 and st < 1200:\n",
    "            time_dic.append('17시-20시')\n",
    "        elif st >= 1200 and st < 1380:\n",
    "            time_dic.append('20시-23시')\n",
    "        elif st >=1380 or st<300:\n",
    "            time_dic.append('23시-3시')\n",
    "    return time_dic  \n",
    "\n",
    "stt = list(test['sched_time'])\n",
    "\n",
    "a = time_dicrete(stt)\n",
    "test['time_discrete'] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 등록기호 매핑\n",
    "# 훈련데이터를 통해 매핑을 진행하였고 수작업으로 진행한 부분이 있어서 코드는 주석처리\n",
    "# 파일을 통해 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 등록기호 매핑\n",
    "\n",
    "# 해당 부분은 학습 데이터의 6월 17~23일까지의 일주일 데이터로 테스트셋의 등록기호를 매핑한 코드입니다.\n",
    "# 작업한 후 몇 작업에 대해선 수작업으로 진행해야되기 때문에 코드화하지 못하였고\n",
    "# 해당파일을 제출하여 읽어오는 방식입니다.\n",
    "\n",
    "# df_afsnt = pd.read_csv('bigcontest/df_afsnt_total_ver10.csv', encoding = 'utf-8', engine = 'python')\n",
    "# df_afsnt[\"sched_time\"] = pd.to_datetime(df_afsnt[\"sched_time\"], format = \"%H:%M:%S\").dt.time\n",
    "# df_afsnt[\"real_time\"] = pd.to_datetime(df_afsnt[\"real_time\"], format = \"%H:%M:%S\").dt.time\n",
    "# df_afsnt = df_afsnt[df_afsnt['date']> '2019-03-31']\n",
    "# df_afsnt_d = df_afsnt[df_afsnt['is_arrive']== False ]\n",
    "# df_afsnt_a = df_afsnt[df_afsnt['is_arrive']== True]\n",
    "# df_afsnt_d = df_afsnt_d[(df_afsnt_d['month']==6) & (df_afsnt_d['day'] < 24) & (df_afsnt_d['day'] > 16)]\n",
    "# df_afsnt_a = df_afsnt_a[(df_afsnt_a['month']==6) & (df_afsnt_a['day'] < 24) & (df_afsnt_a['day'] > 16)]\n",
    "# test['tailnum'] = -999\n",
    "# test['link'] = -999\n",
    "# test_d = test[test['is_arrive']== 'D']\n",
    "# test_a = test[test['is_arrive']== 'A']\n",
    "# df_afsnt_d.index = list(range(len(df_afsnt_d)))\n",
    "# df_afsnt_a.index = list(range(len(df_afsnt_a)))\n",
    "# test_d.index = list(range(len(test_d)))\n",
    "# test_a.index = list(range(len(test_a)))\n",
    "# for i in range(len(test_d)):\n",
    "#    wday = test_d['wday'][i]\n",
    "#    origin = test_d['origin'][i]\n",
    "#    dest = test_d['dest'][i]\n",
    "#    sched_time = test_d['sched_time'][i]\n",
    "#    flight = test_d['flight'][i]\n",
    "#    for j in range(len(df_afsnt_d)):\n",
    "#        if (wday == df_afsnt_d['wday'][j]) & (origin == df_afsnt_d['origin'][j]) & (dest == df_afsnt_d['dest'][j]) & (flight == df_afsnt_d['flight'][j])& (sched_time == df_afsnt_d['sched_time'][j]):\n",
    "#            test_d['tailnum'][i] = df_afsnt_d['tailnum'][j]\n",
    "#            test_d['link'][i] = df_afsnt_d['link'][j]\n",
    "#for i in range(len(test_a)):\n",
    "#    wday = test_a['wday'][i]\n",
    "#    origin = test_a['origin'][i]\n",
    "#    dest = test_a['dest'][i]\n",
    "#    sched_time = test_a['sched_time'][i]\n",
    "#    flight = test_a['flight'][i] \n",
    "#    for j in range(len(df_afsnt_a)):\n",
    "#        if (wday == df_afsnt_a['wday'][j]) & (origin == df_afsnt_a['origin'][j]) & (dest == df_afsnt_a['dest'][j]) & (flight == df_afsnt_a['flight'][j])& (sched_time == df_afsnt_a['sched_time'][j]):\n",
    "#            test_a['tailnum'][i] = df_afsnt_a['tailnum'][j]\n",
    "#            test_a['link'][i] = df_afsnt_a['link'][j]\n",
    "\n",
    "test_link_tailnum = pd.read_csv('bigcontest/test_ref/test_link_tailnum.csv', engine = 'python', encoding = 'cp949')\n",
    "test_link_tailnum[\"sched_time\"] = pd.to_datetime(test_link_tailnum[\"sched_time\"], format = \"%H:%M:%S\").dt.time\n",
    "test_link_tailnum = test_link_tailnum.drop(columns = ['time_discrete','sched_datetime','DLY_RATE','is_delay',\n",
    "                                                     'date'])\n",
    "test = pd.merge(test, test_link_tailnum, on = ['year','month','day','wday','origin','dest','airline',\n",
    "                                               'flight','is_arrive','sched_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 혼잡도 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출도착 구분\n",
    "\n",
    "test_d = test[test['is_arrive']=='D']\n",
    "test_a = test[test['is_arrive']=='A']\n",
    "\n",
    "# +- 30분 기준 혼잡도 변수 생성\n",
    "\n",
    "# 출발기준 혼잡도\n",
    "\n",
    "test_d = test_d.sort_values(['origin','date','sched_time'])\n",
    "test_d.index = list(range(len(test_d)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=30)\n",
    "congestion_d = []\n",
    "\n",
    "for i in range(len(test_d)):\n",
    "    \n",
    "    airport = test_d['origin'][i]\n",
    "    sched_time = test_d['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time + base_time\n",
    "    congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(test_d)-30) else len(test_d) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airport == test_d['origin'][j]) and (lower_time <= test_d['sched_datetime'][j]) and (test_d['sched_datetime'][j] <= upper_time):\n",
    "            congestion_cnt +=1\n",
    "    congestion_d.append(congestion_cnt)\n",
    "    \n",
    "test_d['congestion'] = congestion_d\n",
    "\n",
    "# 도착 기준 혼잡도\n",
    "\n",
    "test_a = test_a.sort_values(['dest','date','sched_time'])\n",
    "test_a.index = list(range(len(test_a)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=30)\n",
    "congestion_a = []\n",
    "\n",
    "for i in range(len(test_a)):\n",
    "    \n",
    "    airport = test_a['dest'][i]\n",
    "    sched_time = test_a['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time + base_time\n",
    "    congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(test_a)-30) else len(test_a) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airport == test_a['dest'][j]) and (lower_time <= test_a['sched_datetime'][j]) and (test_a['sched_datetime'][j] <= upper_time):\n",
    "            congestion_cnt +=1\n",
    "    congestion_a.append(congestion_cnt)\n",
    "    \n",
    "test_a['congestion'] = congestion_a\n",
    "\n",
    "# +- 15분 간격으로 혼잡도 변수 생성\n",
    "\n",
    "# 출발기준 혼잡도\n",
    "\n",
    "test_d = test_d.sort_values(['origin','date','sched_time'])\n",
    "test_d.index = list(range(len(test_d)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=15)\n",
    "congestion_d = []\n",
    "\n",
    "for i in range(len(test_d)):\n",
    "    \n",
    "    airport = test_d['origin'][i]\n",
    "    sched_time = test_d['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time + base_time\n",
    "    congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(test_d)-30) else len(test_d) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airport == test_d['origin'][j]) and (lower_time <= test_d['sched_datetime'][j]) and (test_d['sched_datetime'][j] <= upper_time):\n",
    "            congestion_cnt +=1\n",
    "    congestion_d.append(congestion_cnt)\n",
    "    \n",
    "test_d['congestion_15'] = congestion_d\n",
    "\n",
    "# 도착 기준 혼잡도\n",
    "\n",
    "test_a = test_a.sort_values(['dest','date','sched_time'])\n",
    "test_a.index = list(range(len(test_a)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=15)\n",
    "congestion_a = []\n",
    "\n",
    "for i in range(len(test_a)):\n",
    "    \n",
    "    airport = test_a['dest'][i]\n",
    "    sched_time = test_a['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time + base_time\n",
    "    congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(test_a)-30) else len(test_a) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airport == test_a['dest'][j]) and (lower_time <= test_a['sched_datetime'][j]) and (test_a['sched_datetime'][j] <= upper_time):\n",
    "            congestion_cnt +=1\n",
    "    congestion_a.append(congestion_cnt)\n",
    "    \n",
    "test_a['congestion_15'] = congestion_a\n",
    "\n",
    "test = pd.concat([test_d, test_a], sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# air_sequence 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공항 sequence\n",
    "\n",
    "test_d = test[test['is_arrive']=='D']\n",
    "test_a = test[test['is_arrive']=='A']\n",
    "test_d = test_d.sort_values(['date','origin','sched_time'])\n",
    "test_a = test_a.sort_values(['date','dest','sched_time'])\n",
    "\n",
    "test_d.index = list(range(len(test_d)))\n",
    "test_a.index = list(range(len(test_a)))\n",
    "\n",
    "air_sequence = []\n",
    "x = 0\n",
    "\n",
    "for i in range(len(test_d)):\n",
    "    if i == 0:\n",
    "        air_sequence.append(0)\n",
    "    elif (test_d['date'][i] == test_d['date'][i-1]) and (test_d['origin'][i] == test_d['origin'][i-1]):\n",
    "            if test_d['sched_datetime'][i] > test_d['sched_datetime'][i-1]:\n",
    "                x +=1\n",
    "                air_sequence.append(x)\n",
    "            elif test_d['sched_datetime'][i] == test_d['sched_datetime'][i-1]:\n",
    "                air_sequence.append(x)\n",
    "            elif test_d['sched_datetime'][i] < test_d['sched_datetime'][i-1]:\n",
    "                x = 0\n",
    "                air_sequence.append(x)\n",
    "    \n",
    "    else :\n",
    "        x = 0\n",
    "        air_sequence.append(x)\n",
    "\n",
    "test_d['air_sequence'] = air_sequence\n",
    "\n",
    "air_sequence = []\n",
    "x = 0\n",
    "\n",
    "for i in range(len(test_a)):\n",
    "    if i == 0:\n",
    "        air_sequence.append(0)\n",
    "    elif (test_a['date'][i] == test_a['date'][i-1]) and (test_a['dest'][i] == test_a['dest'][i-1]):\n",
    "            if test_a['sched_datetime'][i] > test_a['sched_datetime'][i-1]:\n",
    "                x +=1\n",
    "                air_sequence.append(x)\n",
    "            elif test_a['sched_datetime'][i] == test_a['sched_datetime'][i-1]:\n",
    "                air_sequence.append(x)\n",
    "            elif test_a['sched_datetime'][i] < test_a['sched_datetime'][i-1]:\n",
    "                x = 0\n",
    "                air_sequence.append(x)\n",
    "    \n",
    "    else :\n",
    "        x = 0\n",
    "        air_sequence.append(x)\n",
    "\n",
    "test_a['air_sequence'] = air_sequence\n",
    "\n",
    "test = pd.concat([test_d, test_a], sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중심성 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 링크테이블\n",
    "\n",
    "# 출발 링크테이블\n",
    "\n",
    "test_d = test[test['is_arrive']=='D']\n",
    "link_table_d = pd.read_csv('bigcontest/test_ref/link_table_d.csv', encoding = 'cp949', engine = 'python')\n",
    "\n",
    "# 도착 링크\n",
    "\n",
    "test_a = test[test['is_arrive']=='A']\n",
    "link_table_a = pd.read_csv('bigcontest/test_ref/link_table_a.csv', encoding = 'cp949', engine = 'python')\n",
    "\n",
    "\n",
    "# 전체 링크\n",
    "\n",
    "link_table = pd.read_csv('bigcontest/test_ref/link_table.csv', encoding = 'cp949', engine = 'python')\n",
    "\n",
    "\n",
    "\n",
    "# 중심성 분석 함수\n",
    "# 가중치 고려\n",
    "\n",
    "def get_degree_centrality(df,arp) :\n",
    "    N = 15\n",
    "    Z = df[df['origin']==arp]['count'].sum()\n",
    "    D = Z/(N-1)\n",
    "    return D\n",
    "\n",
    "\n",
    "# 가중치 고려 x\n",
    "\n",
    "def degree_centrality(df,arp):\n",
    "    N =15\n",
    "    a = df[df['origin']==arp]\n",
    "    D = len((a['origin']+','+a['dest']).unique())/(N-1)\n",
    "    return D\n",
    "\n",
    "# 중심성 분석 \n",
    "\n",
    "arp_list = list(link_table_d['origin'].unique())\n",
    "center_link_d = pd.DataFrame(data=arp_list,columns=['origin'])\n",
    "D_list = []\n",
    "\n",
    "for i in arp_list:\n",
    "    D = get_degree_centrality(link_table_d, i)\n",
    "    D_list.append(D)\n",
    "\n",
    "center_link_d['degree_center_weight'] = D_list\n",
    "\n",
    "# 가중치 고려x\n",
    "\n",
    "N =15\n",
    "arp_list = list(link_table_d['origin'].unique())\n",
    "center_link2_d= pd.DataFrame(data=arp_list,columns=['origin'])\n",
    "D_list = []\n",
    "\n",
    "for i in arp_list:\n",
    "    D = degree_centrality(link_table_d, i)\n",
    "    D_list.append(D)\n",
    "    \n",
    "center_link2_d['degree_center'] = D_list\n",
    "\n",
    "center_link_d_total = pd.merge(center_link_d, center_link2_d)\n",
    "\n",
    "# 원 데이터에 매핑\n",
    "\n",
    "ref_dict = {}\n",
    "\n",
    "for i in range(len(center_link_d_total)):\n",
    "    ref_dict[center_link_d_total['origin'][i]] = center_link_d_total['degree_center_weight'][i]\n",
    "    \n",
    "ref_dict2 = {}\n",
    "for i in range(len(center_link_d_total)):\n",
    "    ref_dict2[center_link_d_total['origin'][i]] = center_link_d_total['degree_center'][i]\n",
    "\n",
    "test_d['degree_center_weight_origin'] = test_d['origin'].map(ref_dict)\n",
    "test_d['degree_center_weight_dest'] = test_d['dest'].map(ref_dict)\n",
    "test_d['degree_center_origin'] = test_d['origin'].map(ref_dict2)\n",
    "test_d['degree_center_dest'] = test_d['dest'].map(ref_dict2)\n",
    "\n",
    "# 중심성 분석 \n",
    "\n",
    "arp_list = list(link_table_a['origin'].unique())\n",
    "center_link_a = pd.DataFrame(data=arp_list,columns=['origin'])\n",
    "D_list = []\n",
    "\n",
    "for i in arp_list:\n",
    "    D = get_degree_centrality(link_table_a, i)\n",
    "    D_list.append(D)\n",
    "\n",
    "center_link_a['degree_center_weight'] = D_list\n",
    "\n",
    "# 가중치 고려x\n",
    "\n",
    "N =15\n",
    "arp_list = list(link_table_a['origin'].unique())\n",
    "center_link2_a= pd.DataFrame(data=arp_list,columns=['origin'])\n",
    "D_list = []\n",
    "\n",
    "for i in arp_list:\n",
    "    D = degree_centrality(link_table_a, i)\n",
    "    D_list.append(D)\n",
    "    \n",
    "center_link2_a['degree_center'] = D_list\n",
    "center_link_a_total = pd.merge(center_link_a, center_link2_a)\n",
    "\n",
    "# 원데이터에 매핑\n",
    "\n",
    "ref_dict = {}\n",
    "\n",
    "for i in range(len(center_link_a_total)):\n",
    "    ref_dict[center_link_a_total['origin'][i]] = center_link_a_total['degree_center_weight'][i]\n",
    "    \n",
    "ref_dict2 = {}\n",
    "for i in range(len(center_link_a_total)):\n",
    "    ref_dict2[center_link_a_total['origin'][i]] = center_link_a_total['degree_center'][i]\n",
    "\n",
    "test_a['degree_center_weight_origin'] = test_a['origin'].map(ref_dict)\n",
    "test_a['degree_center_weight_dest'] = test_a['dest'].map(ref_dict)\n",
    "test_a['degree_center_origin'] = test_a['origin'].map(ref_dict2)\n",
    "test_a['degree_center_dest'] = test_a['dest'].map(ref_dict2)\n",
    "\n",
    "test = pd.concat([test_d,test_a], sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 항공흐름 혼잡도 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 항공흐름 혼잡도 / 출도착 구분 \n",
    "# 15분 전 항공흐름\n",
    "\n",
    "# 출도착 구분\n",
    "\n",
    "test['origin_dest'] = test['origin']+','+test['dest']\n",
    "\n",
    "test_d = test[test['is_arrive']=='D']\n",
    "test_a = test[test['is_arrive']=='A']\n",
    "\n",
    "test_d = test_d.sort_values(['date','origin_dest','sched_time'])\n",
    "test_a = test_a.sort_values(['date','origin_dest','sched_time'])\n",
    "\n",
    "test_d.index = list(range(len(test_d)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=15)\n",
    "air_congestion_d = []\n",
    "\n",
    "for i in range(len(test_d)):\n",
    "    \n",
    "    airway = test_d['origin_dest'][i]\n",
    "    sched_time = test_d['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time \n",
    "    air_congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(test_d)-30) else len(test_d) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airway == test_d['origin_dest'][j]) and (lower_time <= test_d['sched_datetime'][j]) and (test_d['sched_datetime'][j] <= upper_time):\n",
    "            air_congestion_cnt +=1\n",
    "    air_congestion_d.append(air_congestion_cnt)\n",
    "    \n",
    "test_d['air_congestion_15'] = air_congestion_d\n",
    "\n",
    "\n",
    "test_a.index = list(range(len(test_a)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=15)\n",
    "air_congestion_a = []\n",
    "\n",
    "for i in range(len(test_a)):\n",
    "    \n",
    "    airway = test_a['origin_dest'][i]\n",
    "    sched_time = test_a['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time \n",
    "    air_congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(test_a)-30) else len(test_a) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airway == test_a['origin_dest'][j]) and (lower_time <= test_a['sched_datetime'][j]) and (test_a['sched_datetime'][j] <= upper_time):\n",
    "            air_congestion_cnt +=1\n",
    "    air_congestion_a.append(air_congestion_cnt)\n",
    "    \n",
    "test_a['air_congestion_15'] = air_congestion_a\n",
    "\n",
    "test = pd.concat([test_d, test_a], sort= False)\n",
    "\n",
    "# 항공흐름 혼잡도 / 출도착 구분 \n",
    "# 30분 전 항공흐름\n",
    "\n",
    "# 출도착 구분\n",
    "\n",
    "test_d = test[test['is_arrive']=='D']\n",
    "test_a = test[test['is_arrive']=='A']\n",
    "\n",
    "test_d = test_d.sort_values(['date','origin_dest','sched_time'])\n",
    "test_a = test_a.sort_values(['date','origin_dest','sched_time'])\n",
    "\n",
    "test_d.index = list(range(len(test_d)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=30)\n",
    "air_congestion_d = []\n",
    "\n",
    "for i in range(len(test_d)):\n",
    "    \n",
    "    airway = test_d['origin_dest'][i]\n",
    "    sched_time = test_d['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time \n",
    "    air_congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(test_d)-30) else len(test_d) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airway == test_d['origin_dest'][j]) and (lower_time <= test_d['sched_datetime'][j]) and (test_d['sched_datetime'][j] <= upper_time):\n",
    "            air_congestion_cnt +=1\n",
    "    air_congestion_d.append(air_congestion_cnt)\n",
    "    \n",
    "test_d['air_congestion_30'] = air_congestion_d\n",
    "\n",
    "\n",
    "test_a.index = list(range(len(test_a)))\n",
    "\n",
    "base_time = datetime.timedelta(minutes=30)\n",
    "air_congestion_a = []\n",
    "\n",
    "for i in range(len(test_a)):\n",
    "    \n",
    "    airway = test_a['origin_dest'][i]\n",
    "    sched_time = test_a['sched_datetime'][i]\n",
    "    lower_time = sched_time - base_time\n",
    "    upper_time = sched_time \n",
    "    air_congestion_cnt = 0\n",
    "    num = [x if x >= 0 else 0 for x in [i-30]]\n",
    "    num2 = [x if x <= (len(test_a)-30) else len(test_a) for x in [i+30]]\n",
    "    \n",
    "    for j in range(num[0], num2[0],1):\n",
    "        if (airway == test_a['origin_dest'][j]) and (lower_time <= test_a['sched_datetime'][j]) and (test_a['sched_datetime'][j] <= upper_time):\n",
    "            air_congestion_cnt +=1\n",
    "    air_congestion_a.append(air_congestion_cnt)\n",
    "    \n",
    "test_a['air_congestion_30'] = air_congestion_a\n",
    "\n",
    "test = pd.concat([test_d, test_a], sort= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 항공사의 일별 연결정도 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 항공사의 일별 연결정도 변수\n",
    "\n",
    "test_d = test[test['is_arrive']=='D']\n",
    "test_a = test[test['is_arrive']=='A']\n",
    "\n",
    "# 출도착 일별 평균 비행기 개수\n",
    "\n",
    "dd = pd.read_csv('bigcontest/test_ref/dd.csv', engine = 'python', encoding = 'cp949')\n",
    "aa = pd.read_csv('bigcontest/test_ref/aa.csv', engine = 'python', encoding = 'cp949')\n",
    "\n",
    "x = test_d.pivot_table(index = ['date','airline'],aggfunc = 'count', values = 'is_arrive')\n",
    "x = x.reset_index(['date','airline'])\n",
    "x.columns = ['date','airline','count']\n",
    "\n",
    "y = test_a.pivot_table(index = ['date','airline'],aggfunc = 'count', values = 'is_arrive')\n",
    "y = y.reset_index(['date','airline'])\n",
    "y.columns = ['date','airline','count']\n",
    "\n",
    "link_count = []\n",
    "for i in range(len(x)):\n",
    "    a = x['count'][i]\n",
    "    b = float(dd[dd['airline']==x['airline'][i]]['count'].values)\n",
    "    cnt = a/b\n",
    "    link_count.append(cnt)\n",
    "x['link_count'] = link_count\n",
    "\n",
    "link_count = []\n",
    "for i in range(len(y)):\n",
    "    a = y['count'][i]\n",
    "    b = float(aa[aa['airline']==y['airline'][i]]['count'].values)\n",
    "    cnt = a/b\n",
    "    link_count.append(cnt)\n",
    "y['link_count'] = link_count\n",
    "\n",
    "x = x.drop(columns = 'count')\n",
    "y = y.drop(columns = 'count')\n",
    "\n",
    "test_d = pd.merge(test_d,x, on = ['date','airline'])\n",
    "test_a = pd.merge(test_a, y, on = ['date','airline'])\n",
    "\n",
    "test = pd.concat([test_d, test_a], sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 항공사별 time sequence 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 항공사별 sequence 생성\n",
    "\n",
    "test_d = test[test['is_arrive']=='D']\n",
    "test_a = test[test['is_arrive']=='A']\n",
    "\n",
    "test_d = test_d.sort_values(['date','airline','sched_time'])\n",
    "test_a = test_a.sort_values(['date','airline','sched_time'])\n",
    "\n",
    "test_d.index = list(range(len(test_d)))\n",
    "test_a.index = list(range(len(test_a)))\n",
    "\n",
    "# 출발\n",
    "\n",
    "air_link = []\n",
    "x = 0\n",
    "\n",
    "for i in range(len(test_d)):\n",
    "    if i == 0:\n",
    "        air_link.append(0)\n",
    "    \n",
    "    elif test_d['sched_datetime'][i] > test_d['sched_datetime'][i-1]:\n",
    "        if test_d['day'][i] == test_d['day'][i-1]:\n",
    "            x += 1\n",
    "            air_link.append(x)\n",
    "        elif test_d['day'][i] > test_d['day'][i-1]:\n",
    "            x = 0\n",
    "            air_link.append(x)\n",
    "        elif test_d['day'][i] < test_d['day'][i-1]:\n",
    "            x = 0\n",
    "            air_link.append(x)\n",
    "        \n",
    "    elif test_d['sched_datetime'][i] == test_d['sched_datetime'][i-1]:\n",
    "        air_link.append(x)\n",
    "        \n",
    "    elif test_d['sched_datetime'][i] < test_d['sched_datetime'][i-1]:\n",
    "        x = 0\n",
    "        air_link.append(x)\n",
    "\n",
    "test_d['air_link'] = air_link\n",
    "\n",
    "# 도착\n",
    "\n",
    "air_link = []\n",
    "x = 0\n",
    "\n",
    "for i in range(len(test_a)):\n",
    "    if i == 0:\n",
    "        air_link.append(0)\n",
    "    \n",
    "    elif test_a['sched_datetime'][i] > test_a['sched_datetime'][i-1]:\n",
    "        if test_a['day'][i] == test_a['day'][i-1]:\n",
    "            x += 1\n",
    "            air_link.append(x)\n",
    "        elif test_a['day'][i] > test_a['day'][i-1]:\n",
    "            x = 0\n",
    "            air_link.append(x)\n",
    "        elif test_a['day'][i] < test_a['day'][i-1]:\n",
    "            x = 0\n",
    "            air_link.append(x)\n",
    "        \n",
    "    elif test_a['sched_datetime'][i] == test_a['sched_datetime'][i-1]:\n",
    "        air_link.append(x)\n",
    "        \n",
    "    elif test_a['sched_datetime'][i] < test_a['sched_datetime'][i-1]:\n",
    "        x = 0\n",
    "        air_link.append(x)\n",
    "        \n",
    "\n",
    "test_a['air_link'] = air_link\n",
    "\n",
    "\n",
    "# 공항별 항공사별 sequence 생성\n",
    "\n",
    "test_d = test_d.sort_values(['date','origin','airline','sched_time'])\n",
    "test_a = test_a.sort_values(['date','dest','airline','sched_time'])\n",
    "\n",
    "test_d.index = list(range(len(test_d)))\n",
    "test_a.index = list(range(len(test_a)))\n",
    "\n",
    "air_place_link = []\n",
    "x = 0\n",
    "\n",
    "for i in range(len(test_d)):\n",
    "    if i == 0:\n",
    "        air_place_link.append(0)\n",
    "    \n",
    "    elif (test_d['origin'][i] == test_d['origin'][i-1]) and (test_d['date'][i] == test_d['date'][i-1]) and (test_d['airline'][i] == test_d['airline'][i-1]):\n",
    "        if test_d['sched_datetime'][i] > test_d['sched_datetime'][i-1]:\n",
    "            x += 1\n",
    "            air_place_link.append(x)\n",
    "        elif test_d['sched_datetime'][i] == test_d['sched_datetime'][i-1]:\n",
    "            air_place_link.append(x)\n",
    "        elif test_d['sched_datetime'][i] < test_d['sched_datetime'][i-1]:\n",
    "            x = 0\n",
    "            air__placelink.append(x)\n",
    "        \n",
    "    else :\n",
    "        x = 0\n",
    "        air_place_link.append(x)\n",
    "\n",
    "test_d['air_place_link'] = air_place_link\n",
    "\n",
    "air_place_link = []\n",
    "x = 0\n",
    "\n",
    "for i in range(len(test_a)):\n",
    "    if i == 0:\n",
    "        air_place_link.append(0)\n",
    "    \n",
    "    elif (test_a['dest'][i] == test_a['dest'][i-1]) and (test_a['date'][i] == test_a['date'][i-1]) and (test_a['airline'][i] == test_a['airline'][i-1]):\n",
    "        if test_a['sched_datetime'][i] > test_a['sched_datetime'][i-1]:\n",
    "            x += 1\n",
    "            air_place_link.append(x)\n",
    "        elif test_a['sched_datetime'][i] == test_a['sched_datetime'][i-1]:\n",
    "            air_place_link.append(x)\n",
    "        elif test_a['sched_datetime'][i] < test_a['sched_datetime'][i-1]:\n",
    "            x = 0\n",
    "            air__placelink.append(x)\n",
    "        \n",
    "    else :\n",
    "        x = 0\n",
    "        air_place_link.append(x)\n",
    "\n",
    "test_a['air_place_link'] = air_place_link\n",
    "\n",
    "test = pd.concat([test_d, test_a], sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 거리, 거리중심성 및 기타 공항 정보 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 거리 매핑 및 거리중심성 \n",
    "\n",
    "distance = pd.read_csv('bigcontest/test_ref/airport_distance.csv', engine = 'python', encoding = 'cp949')\n",
    "distance['origin_dest'] = distance['origin']+','+distance['dest']\n",
    "\n",
    "ref_dict = {}\n",
    "\n",
    "for i in range(len(distance)):\n",
    "    ref_dict[distance['origin_dest'][i]] = distance['distance_km'][i]\n",
    "\n",
    "test['distance_km'] = test['origin_dest'].map(ref_dict)\n",
    "\n",
    "# 거리중심성 테입블 파일\n",
    "\n",
    "center = pd.read_csv('bigcontest/test_ref/center.csv', encoding = 'cp949', engine = 'python')\n",
    "\n",
    "# 매핑\n",
    "\n",
    "ref_dict = {}\n",
    "\n",
    "for i in range(len(center)):\n",
    "    ref_dict[center['origin'][i]] = center['distance_center'][i]\n",
    "\n",
    "test['distance_center'] = test['origin'].map(ref_dict)\n",
    "\n",
    "# 거리중심성 분석\n",
    "# 어떤 테이블이 있을건데 이것은 출발 - 도착 - 거리를 보여주는 데이터프레임 = df_distance \n",
    "\n",
    "origin_unique = (test['origin']).unique()\n",
    "\n",
    "def get_distance_centrality(origin):\n",
    "    N = 15\n",
    "    df_distance = distance[distance['origin']==origin]\n",
    "    df_distance.index = list(range(len(df_distance)))\n",
    "    distance_sum = 0\n",
    "    for i in range(len(df_distance)):\n",
    "        distance_sum += df_distance['distance_km'][i]\n",
    "            \n",
    "    distance_sum_inverse = (distance_sum)**(-1)\n",
    "    distance_center = (N-1)*distance_sum_inverse\n",
    "    return distance_center \n",
    "\n",
    "# 중심성 분석 \n",
    "\n",
    "origin_unique = (test['origin']).unique()\n",
    "center_distance = pd.DataFrame(data=origin_unique,columns=['origin'])\n",
    "D_list = []\n",
    "\n",
    "for i in origin_unique:\n",
    "    D = get_distance_centrality(i)\n",
    "    D_list.append(D)\n",
    "\n",
    "center_distance['distance_center'] = D_list\n",
    "\n",
    "ref_dict = {}\n",
    "\n",
    "for i in range(len(center_distance)):\n",
    "    ref_dict[center_distance['origin'][i]] = center_distance['distance_center'][i]\n",
    "\n",
    "test['distance_center_weight'] = test['origin'].map(ref_dict)\n",
    "\n",
    "# 공항정보 매핑\n",
    "\n",
    "info = pd.read_csv('bigcontest/test_ref/공항활주로_부지면적.csv', engine='python',encoding='cp949')\n",
    "test = pd.merge(test, info, on=['origin','year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일별 비행기 운항횟수 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하루당 해당 비행기 운행횟수\n",
    "\n",
    "test_d = test[test['is_arrive']=='D']\n",
    "test_a = test[test['is_arrive']=='A']\n",
    "\n",
    "d_table = test_d.pivot_table(index=['date','tailnum'],aggfunc='count',values='is_arrive')\n",
    "d_table = d_table.reset_index(['date','tailnum'])\n",
    "d_table.columns = ['date','tailnum','cnt_per_day']\n",
    "\n",
    "a_table = test_a.pivot_table(index=['date','tailnum'],aggfunc='count',values='is_arrive')\n",
    "a_table = a_table.reset_index(['date','tailnum'])\n",
    "a_table.columns = ['date','tailnum','cnt_per_day']\n",
    "\n",
    "test_d2 = pd.merge(test_d, d_table, on = ['date','tailnum'])\n",
    "test_a2 = pd.merge(test_a, a_table, on = ['date','tailnum'])\n",
    "\n",
    "test = pd.concat([test_d2,test_a2], sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기타 시간 및 요일 변수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['is_flight_T'] = np.where(test['flight'].str.endswith(\"T\"), 1, 0)\n",
    "test['is_flight_M'] = np.where(test['flight'].str.endswith(\"M\"), 1, 0)\n",
    "test['is_flight_F'] = np.where(test['flight'].str.endswith(\"F\"), 1, 0)\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "test['sched_datetime'] = pd.to_datetime(test['sched_datetime'])\n",
    "\n",
    "# 월\n",
    "test['month_sin'] = np.sin(2*test['sched_datetime'].dt.month*np.pi / 12 )\n",
    "test['month_cos'] = np.cos(2*test['sched_datetime'].dt.month*np.pi / 12 )\n",
    "\n",
    "# 요일\n",
    "test['sched_datetime'] = pd.to_datetime(test['sched_datetime'])\n",
    "test['is_weekend'] = np.where((test['sched_datetime'].dt.weekday == 6) | (test['sched_datetime'].dt.weekday == 5), True, False)\n",
    "\n",
    "# 시간\n",
    "test['time_sin'] = 60 * np.sin(2*np.pi*test['sched_datetime'].dt.hour / 24) + \\\n",
    "                        np.sin(2*test['sched_datetime'].dt.minute*np.pi / 60)\n",
    "test['time_cos'] = 60 * np.cos(2*test['sched_datetime'].dt.hour*np.pi / 24) + \\\n",
    "                        np.cos(2*np.pi*test['sched_datetime'].dt.minute / 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 해발 고도\n",
    "df_altitude = pd.DataFrame(pd.Series({\n",
    "    '김포': 18,\n",
    "    '김해': 4,\n",
    "    '제주': 36,\n",
    "    '대구': 35.4,\n",
    "    '울산': 12.9,\n",
    "    '청주': 58,\n",
    "    '양양': 73.5,\n",
    "    '무안': 23.7,\n",
    "    '광주': 12.8,\n",
    "    '여수': 20,\n",
    "    '사천': 7.6,\n",
    "    '포항': 21.3,\n",
    "    '군산': 8.8,\n",
    "    '원주': 100,\n",
    "    '인천': 7\n",
    "})).reset_index().rename(columns = {'index': 'airport', 0: 'alt'})\n",
    "\n",
    "test = pd.merge(test, df_altitude, how = \"left\", left_on = 'origin', right_on = 'airport', suffixes = ('_origin', '_dest'))\n",
    "test = pd.merge(test, df_altitude, how = \"left\", left_on = 'dest', right_on = 'airport', suffixes = ('_origin', '_dest'))\n",
    "test.drop(['airport_origin', 'airport_dest'], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# is_변수 True False로 변환\n",
    "test[\"is_arrive\"] = np.where(test[\"is_arrive\"] == \"A\", True, False)\n",
    "\n",
    "\n",
    "# 황금연휴 추가\n",
    "\n",
    "test['is_goldentime'] = test['date'].isin([\"2017-01-26\", \"2017-01-27\", \"2017-01-28\", \"2017-01-29\", \"2017-01-30\", \"2017-01-31\", \"2017-05-05\", \"2017-05-06\", \"2017-05-07\", \"2017-08-15\",\n",
    " \"2017-09-29\", \"2017-09-30\", \"2017-10-01\", \"2017-10-02\", \"2017-10-03\", \"2017-10-04\", \"2017-10-05\", \"2017-10-06\", \"2017-10-07\", \"2017-10-08\", \"2017-10-09\", \"2017-10-10\", \n",
    "                                                   \"2017-12-25\", \"2018-01-01\", \"2018-02-14\", \"2018-02-15\", \"2018-02-16\", \"2018-02-17\", \"2018-02-18\", \"2018-02-19\", \"2018-03-01\",\n",
    " \"2018-05-05\", \"2018-05-07\", \"2018-05-22\",\n",
    " \"2018-06-06\", \"2018-06-13\", \"2018-08-15\", \"2018-09-21\", \"2018-09-22\", \"2018-09-23\", \"2018-09-24\", \"2018-09-25\", \"2018-09-26\", \"2018-09-27\", \n",
    " \"2018-10-03\", \"2018-10-09\", \"2018-12-25\", \n",
    " \"2019-01-01\", \"2019-02-01\", \"2019-02-02\", \"2019-02-03\", \"2019-02-04\", \"2019-02-05\", \"2019-02-06\", \"2019-02-07\",\n",
    " \"2019-03-01\", \"2019-05-04\", \"2019-05-05\", \"2019-05-06\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전 비행기와의 시간 차이 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연결 비행기에 있어서 전 비행기와의 시간차이 및 거리를 고려한 시간차이 \n",
    "\n",
    "\n",
    "test_d = test[test['is_arrive']==False]\n",
    "test_a = test[test['is_arrive']==True]\n",
    "\n",
    "# 출발인경우\n",
    "\n",
    "test_d_sorted = test_d.sort_values(['date','tailnum','sched_time'])\n",
    "test_d_sorted.index = list(range(len(test_d_sorted)))\n",
    "\n",
    "time_diff = []\n",
    "time_diff_distance = []\n",
    "\n",
    "for i in range(len(test_d_sorted)):\n",
    "    if test_d_sorted['link'][i] == 0 :\n",
    "        time_diff.append(0)\n",
    "        time_diff_distance.append(0)\n",
    "    \n",
    "    elif test_d_sorted['tailnum'][i] != test_d_sorted['tailnum'][i-1]:\n",
    "        time_diff.append(0)\n",
    "        time_diff_distance.append(0)\n",
    "\n",
    "    else :\n",
    "        time_diff_sec = (test_d_sorted['sched_datetime'][i] - test_d_sorted['sched_datetime'][i-1]).seconds\n",
    "        time_diff_min = int(time_diff_sec/60)\n",
    "        time_diff.append(time_diff_min)\n",
    "        \n",
    "        time_diff_dis = time_diff_min/test_d_sorted['distance_km'][i-1]\n",
    "        time_diff_distance.append(time_diff_dis)\n",
    "        \n",
    "test_d_sorted['time_diff'] = time_diff\n",
    "test_d_sorted['time_diff_distance'] = time_diff_distance\n",
    "\n",
    "# 도착인경우\n",
    "\n",
    "test_a_sorted = test_a.sort_values(['date','tailnum','sched_time'])\n",
    "test_a_sorted.index = list(range(len(test_a_sorted)))\n",
    "\n",
    "time_diff = []\n",
    "time_diff_distance = []\n",
    "\n",
    "for i in range(len(test_a_sorted)):\n",
    "    if test_a_sorted['link'][i] == 0 :\n",
    "        time_diff.append(0)\n",
    "        time_diff_distance.append(0)\n",
    "    \n",
    "    elif test_a_sorted['tailnum'][i] != test_a_sorted['tailnum'][i-1]:\n",
    "        time_diff.append(0)\n",
    "        time_diff_distance.append(0)\n",
    "           \n",
    "    else :\n",
    "        time_diff_sec = (test_a_sorted['sched_datetime'][i] - test_a_sorted['sched_datetime'][i-1]).seconds\n",
    "        time_diff_min = int(time_diff_sec/60)\n",
    "        time_diff.append(time_diff_min)\n",
    "        \n",
    "        time_diff_dis = time_diff_min/test_a_sorted['distance_km'][i-1]\n",
    "        time_diff_distance.append(time_diff_dis)\n",
    "        \n",
    "test_a_sorted['time_diff'] = time_diff\n",
    "test_a_sorted['time_diff_distance'] = time_diff_distance\n",
    "\n",
    "test = pd.concat([test_d_sorted, test_a_sorted], sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 항공편 지연비율 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_d = test[test['is_arrive']==False]\n",
    "test_a = test[test['is_arrive']==True]\n",
    "\n",
    "d = pd.read_csv('bigcontest/test_ref/flight_dly_d.csv', engine = 'python', encoding = 'cp949')\n",
    "a = pd.read_csv('bigcontest/test_ref/flight_dly_a.csv', engine = 'python', encoding = 'cp949')\n",
    "\n",
    "\n",
    "test_d = pd.merge(test_d, d, on = 'flight', how = 'left')\n",
    "test_d['dly_por'].fillna(d['dly_por'].mean(), inplace = True)\n",
    "test_a = pd.merge(test_a, a, on = 'flight', how = 'left')\n",
    "test_a['dly_por'].fillna(a['dly_por'].mean(), inplace = True)\n",
    "test = pd.concat([test_d, test_a], sort=False)\n",
    "\n",
    "test.to_csv('bigcontest/testset2.csv', index=False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 트레이닝 셋에 기상 매핑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  학습을 목적으로 17년~19년 6월 데이터 셋에 기상을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_for_train=pd.read_csv('bigcontest/airport_weather.csv',encoding='cp949')\n",
    "weather_for_train.time_slot=pd.to_datetime(weather_for_train.time_slot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기상변수 이름 테스트 셋과 동일하게 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_for_train.rename({'temp':'pred_temp','dew':'pred_dew'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 습도 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_for_train['mist']=weather_for_train.pred_temp-weather_for_train.pred_dew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파생변수 - 전 시간대와 온도차 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#이슬점 차\n",
    "\n",
    "def create_diff_dew(df):\n",
    "    dew = list(df.pred_dew)\n",
    "    # 첫 번째 행은 비교할 전 시간대가 없으므로 기온차 값을 0으로 만들기 위해 자기 자신값과 비교\n",
    "    dew.insert(0, dew[0])\n",
    "    # 맨 뒤 값 제거\n",
    "    dew.pop() \n",
    "    df['before_dew'] = dew\n",
    "    # 현재 시간대 기온 - 이전 시간대 기온\n",
    "    diff_list = list(df.pred_dew - df.before_dew)\n",
    "    # 공항별 sorting했기 때문에 각 공항의 첫 번째 행을 모두 0으로 만들어주기 위함.\n",
    "    firstday_list = []\n",
    "    for arp in list(set(df.mapping_arp)):\n",
    "        firstday_list.append(df[df.mapping_arp == arp].index[0])\n",
    "    for i in firstday_list:\n",
    "        diff_list[i] = 0\n",
    "    df['diff_dew'] = diff_list\n",
    "    df.drop('before_dew', axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 기온 차\n",
    "def create_diff_temp(df):\n",
    "    temp = list(df.pred_temp)\n",
    "    # 첫 번째 행은 비교할 전 시간대가 없으므로 기온차 값을 0으로 만들기 위해 자기 자신값과 비교\n",
    "    temp.insert(0, temp[0])\n",
    "    # 맨 뒤 값 제거\n",
    "    temp.pop() \n",
    "    df['before_temp'] = temp\n",
    "    # 현재 시간대 기온 - 이전 시간대 기온\n",
    "    diff_list = list(df.pred_temp - df.before_temp)\n",
    "    # 공항별 sorting했기 때문에 각 공항의 첫 번째 행을 모두 0으로 만들어주기 위함.\n",
    "    firstday_list = []\n",
    "    for arp in list(set(df.mapping_arp)):\n",
    "        firstday_list.append(df[df.mapping_arp == arp].index[0])\n",
    "    for i in firstday_list:\n",
    "        diff_list[i] = 0\n",
    "    df['diff_temp'] = diff_list\n",
    "    df.drop('before_temp', axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_for_train.sort_values(['mapping_arp','time_slot'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weather_for_train =  create_diff_temp(weather_for_train)\n",
    "weather_for_train = create_diff_dew(weather_for_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_add_weather=pd.read_csv('bigcontest/df_afsnt_total_ver10.csv',encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_add_weather.drop(['pred_temp','diff_temp'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_add_weather.sched_datetime=train_add_weather.sched_datetime+':00'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 매핑용 time_slot 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_slot(date):\n",
    "    m = date.split(' ')[1].split(':')[1]\n",
    "    # 30분 미만일 때 00분으로\n",
    "    if int(m) < 30:\n",
    "        result = date[:13]+':00:00'\n",
    "    # 30분 이상일 때 다음 시간대로 넘어감.\n",
    "    else:\n",
    "        # ex) 7시->07시\n",
    "        if len(str(int(date[11:13]))) == 1:\n",
    "            # 9시->010시 방지.\n",
    "            if date[11:13]=='09':\n",
    "                result = date[:11]+str(int(date[11:13])+1)+':00:00'\n",
    "            else:\n",
    "                result = date[:11]+'0'+str(int(date[11:13])+1)+':00:00'\n",
    "        # ex) 23시 35분->23시 00분,\n",
    "        elif date[11:13]=='23':\n",
    "            result = date[:13]+':00:00'\n",
    "        else: \n",
    "            result = date[:11]+str(int(date[11:13])+1)+':00:00'\n",
    "    return result#### 매핑용 time_slot 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 매핑용 기상 공항 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_add_weather['time_slot'] = train_add_weather.sched_datetime.apply(create_time_slot)\n",
    "train_add_weather['mapping_arp'] = train_add_weather.origin.map({'포항': '울산', '사천': '여수',\n",
    "                                           '군산': '무안', '원주': '김포',\n",
    "                                           '김해': '울산', '대구': '울산',\n",
    "                                           '청주': '김포', '광주': '무안',\n",
    "                                           '김포': '김포', '무안': '무안',\n",
    "                                           '양양': '양양', '여수': '여수',\n",
    "                                           '울산': '울산', '인천': '인천',\n",
    "                                           '제주': '제주'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실제 기상 매핑 완료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_for_train.time_slot = weather_for_train.time_slot.apply(str)\n",
    "train_add_weather = pd.merge(train_add_weather, weather_for_train, on=['mapping_arp','time_slot'], how='left')\n",
    "train_add_weather.drop(['mapping_arp','time_slot'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_add_weather.to_csv('df_afsnt_total_ver10+weather.csv',index=False,encoding='CP949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 셋 매핑용 기상 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19년 9월 기상 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  19년 9월 기상 예측을 위해 15년도~19년도의 8월, 9월, 10월 시간별/공항별 기상을 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather=pd.read_csv('bigcontest/airport_weather.csv',encoding='cp949')\n",
    "encode_case=pd.get_dummies(weather.mapping_arp)\n",
    "weather=pd.concat([weather,encode_case],axis=1)\n",
    "# 범주형 변수인 공항을 원핫 인코딩으로 변환\n",
    "\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시간을 연,월,일,시간대로 나눠주어서 X feature로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time 을 시간 단위 별로 구분해주는 함수\n",
    "def date_segmentation(data):\n",
    "    ls_date=list(data['time_slot'])\n",
    "\n",
    "    월=[]\n",
    "    시간=[]\n",
    "    시간_2=[]\n",
    "\n",
    "    일시=[]\n",
    "    일=[]\n",
    "    연=[]\n",
    "\n",
    "#for i in range(len(ls_date)):\n",
    "#    연.append(str(ls_date[i]).split('-')[0])\n",
    "\n",
    "    for i in range(len(ls_date)):\n",
    "        연.append(str(ls_date[i]).split('-')[0])\n",
    "        \n",
    "    for i in range(len(ls_date)):\n",
    "        월.append(str(ls_date[i]).split('-')[1])\n",
    "    for i in range(len(ls_date)):\n",
    "        시간.append(str(ls_date[i]).split(' ')[1])\n",
    "\n",
    "    for i in range(len(ls_date)):\n",
    "        시간_2.append(str(시간[i]).split(':')[0])\n",
    "\n",
    "    \n",
    "    for i in range(len(ls_date)):\n",
    "        일시.append(str(ls_date[i]).split(' ')[0])\n",
    "\n",
    "    for i in range(len(ls_date)):    \n",
    "        일.append(str(일시[i]).split('-')[2])\n",
    "\n",
    "\n",
    "    data['연']=연\n",
    "    data['월']=월\n",
    "    data['일']=일\n",
    "    data['시각']=시간_2\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weather=date_segmentation(weather)\n",
    "weather=weather.sort_values(by=['time_slot','mapping_arp'])\n",
    "weather.reset_index(drop=True,inplace=True)\n",
    "\n",
    "weather.set_index('time_slot',inplace=True)\n",
    "\n",
    "weather_sep=weather[weather['월'].isin(['08','09'])]\n",
    "#test 셋인 8월의 날씨를 학습하는 weather_june과\n",
    "#실제 공모전 validation 답안 제출을 위한 학습하는 데이터셋 weather_sep을 구분하여 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9월 예측 구간 온도 예측 By 8,9월 기상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test=weather_sep['2019-09-01':'2019-09-09'] #검증 구간\n",
    "\n",
    "train=weather_sep['2015-08-01':'2019-09-09'] # 학습 구간 \n",
    "# 실제 공모전 및 제출 기간을 고려하여 validation의 구간 결정\n",
    "\n",
    "\n",
    "X_train = train.drop(['mapping_arp','temp','dew'],axis=1).values[:]\n",
    "y_train = train['temp'].values[:]\n",
    "    \n",
    "X_test = np.array(test.drop(['mapping_arp','temp','dew'],axis=1).values[:])\n",
    "y_test = np.array(test['temp'].values[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM 모델을 통해 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = lgb.Dataset(X_train, label = y_train) \n",
    "test_ds = lgb.Dataset(X_test, label = y_test) \n",
    "params = {'learning_rate': '0.254', \n",
    "          'max_depth': 3, \n",
    "          'boosting': 'gbdt', \n",
    "          'objective': 'regression', \n",
    "          'metric': 'rmse', \n",
    "          'is_training_metric': True, \n",
    "          'num_leaves': 30, \n",
    "          'feature_fraction': '0.01',\n",
    "          'bagging_fraction': '0.036',\n",
    "          \"bagging_seed\" : 5,\n",
    "          'bagging_freq': 20, \n",
    "          'seed':3}\n",
    "\n",
    "model_temp = lgb.train(params, train_ds, 1000, test_ds,\\\n",
    "                  verbose_eval=100, early_stopping_rounds=200)\n",
    "\n",
    "predict_train = model_temp.predict(X_train)\n",
    "predict_test = model_temp.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predict_test)\n",
    "\n",
    "print('rmse: ', np.sqrt(mse))\n",
    "\n",
    "\n",
    "#생성된 모델을 통해 6월 15일~ 6월 30일 구간의 기상 값을 예측\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9월 예측 구간 이슬점 예측 By 8,9월 기상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test=weather_sep['2019-09-01':'2019-09-09'] #검증 구간\n",
    "\n",
    "train=weather_sep['2015-08-01':'2019-09-09'] # 학습 구간 \n",
    "# 실제 공모전 및 제출 기간을 고려하여 validation의 구간 결정\n",
    "\n",
    "\n",
    "X_train = train.drop(['mapping_arp','dew','temp'],axis=1).values[:]\n",
    "y_train = train['dew'].values[:]\n",
    "    \n",
    "X_test = np.array(test.drop(['mapping_arp','dew','temp'],axis=1).values[:])\n",
    "y_test = np.array(test['dew'].values[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM 모델을 통해 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = lgb.Dataset(X_train, label = y_train) \n",
    "test_ds = lgb.Dataset(X_test, label = y_test) \n",
    "params = {'learning_rate': '0.254', \n",
    "          'max_depth': 3, \n",
    "          'boosting': 'gbdt', \n",
    "          'objective': 'regression', \n",
    "          'metric': 'rmse', \n",
    "          'is_training_metric': True, \n",
    "          'num_leaves': 30, \n",
    "          'feature_fraction': '0.01',\n",
    "          'bagging_fraction': '0.036',\n",
    "          \"bagging_seed\" : 5,\n",
    "          'bagging_freq': 20, \n",
    "          'seed':3}\n",
    "\n",
    "model_dew = lgb.train(params, train_ds, 1000, test_ds,\\\n",
    "                  verbose_eval=100, early_stopping_rounds=200)\n",
    "\n",
    "predict_train = model_dew.predict(X_train)\n",
    "predict_test = model_dew.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predict_test)\n",
    "\n",
    "print('rmse: ', np.sqrt(mse))\n",
    "\n",
    "\n",
    "#생성된 모델을 통해 6월 15일~ 6월 30일 구간의 기상 값을 예측\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실제 기상 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### AFSNT_DLY 예측 구간용 X_feature 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 공모전 평가 기간인 9월 16일~ 9월 30일 용 예측 기상 추출 후 매핑\n",
    "from datetime import timedelta\n",
    "test_period = weather['2018-09-15':'2018-09-30']\n",
    "test_period.reset_index(inplace=True)\n",
    "test_period['time_slot']=pd.to_datetime(test_period.time_slot)\n",
    "test_period.time_slot =test_period.time_slot  + timedelta(days = 366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_period['연']=2019\n",
    "X_test = np.array(test_period[['김포', '무안', '양양', '여수', '울산', '인천', '제주', '연', '월', '일',\n",
    "       '시각']].values[:])\n",
    "pred_temp = model_temp.predict(X_test)\n",
    "pred_dew = model_dew.predict(X_test)\n",
    "test_period.drop('temp',axis=1,inplace=True)\n",
    "test_period['pred_temp']=pred_temp\n",
    "test_period.drop('dew',axis=1,inplace=True)\n",
    "test_period['pred_dew']=pred_dew\n",
    "test_period.head()\n",
    "\n",
    "#9월 16일부터 15일 간 00시부터 23시까지의 예측된 온도 값 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_period['mist']=pred_temp-pred_dew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파생변수 - 전 시간대와 온도차 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이슬점 차\n",
    "\n",
    "def create_diff_dew(df):\n",
    "    dew = list(df.pred_dew)\n",
    "    # 첫 번째 행은 비교할 전 시간대가 없으므로 기온차 값을 0으로 만들기 위해 자기 자신값과 비교\n",
    "    dew.insert(0, dew[0])\n",
    "    # 맨 뒤 값 제거\n",
    "    dew.pop() \n",
    "    df['before_dew'] = dew\n",
    "    # 현재 시간대 기온 - 이전 시간대 기온\n",
    "    diff_list = list(df.pred_dew - df.before_dew)\n",
    "    # 공항별 sorting했기 때문에 각 공항의 첫 번째 행을 모두 0으로 만들어주기 위함.\n",
    "    firstday_list = []\n",
    "    for arp in list(set(df.mapping_arp)):\n",
    "        firstday_list.append(df[df.mapping_arp == arp].index[0])\n",
    "    for i in firstday_list:\n",
    "        diff_list[i] = 0\n",
    "    df['diff_dew'] = diff_list\n",
    "    df.drop('before_dew', axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 기온 차\n",
    "def create_diff_temp(df):\n",
    "    temp = list(df.pred_temp)\n",
    "    # 첫 번째 행은 비교할 전 시간대가 없으므로 기온차 값을 0으로 만들기 위해 자기 자신값과 비교\n",
    "    temp.insert(0, temp[0])\n",
    "    # 맨 뒤 값 제거\n",
    "    temp.pop() \n",
    "    df['before_temp'] = temp\n",
    "    # 현재 시간대 기온 - 이전 시간대 기온\n",
    "    diff_list = list(df.pred_temp - df.before_temp)\n",
    "    # 공항별 sorting했기 때문에 각 공항의 첫 번째 행을 모두 0으로 만들어주기 위함.\n",
    "    firstday_list = []\n",
    "    for arp in list(set(df.mapping_arp)):\n",
    "        firstday_list.append(df[df.mapping_arp == arp].index[0])\n",
    "    for i in firstday_list:\n",
    "        diff_list[i] = 0\n",
    "    df['diff_temp'] = diff_list\n",
    "    df.drop('before_temp', axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_period.sort_values(['mapping_arp','time_slot'], inplace=True)\n",
    "test_period =  create_diff_temp(test_period)\n",
    "test_period = create_diff_dew(test_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_period.to_csv('bigcontest/test_period_pred_weather.csv',index=False,encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv('bigcontest/test_period_pred_weather.csv', encoding='cp949')\n",
    "df_pred.reset_index(inplace=True)\n",
    "df_pred.drop('index', axis=1, inplace=True)\n",
    "df_pred.drop(['김포','무안','양양','여수','울산','인천','제주','연','월','일','시각'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dly=pd.read_csv('bigcontest/testset2.csv',encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 매핑용 time_slot 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_slot(date):\n",
    "    m = date.split(' ')[1].split(':')[1]\n",
    "    # 30분 미만일 때 00분으로\n",
    "    if int(m) < 30:\n",
    "        result = date[:13]+':00:00'\n",
    "    # 30분 이상일 때 다음 시간대로 넘어감.\n",
    "    else:\n",
    "        # ex) 7시->07시\n",
    "        if len(str(int(date[11:13]))) == 1:\n",
    "            # 9시->010시 방지.\n",
    "            if date[11:13]=='09':\n",
    "                result = date[:11]+str(int(date[11:13])+1)+':00:00'\n",
    "            else:\n",
    "                result = date[:11]+'0'+str(int(date[11:13])+1)+':00:00'\n",
    "        # ex) 23시 35분->23시 00분,\n",
    "        elif date[11:13]=='23':\n",
    "            result = date[:13]+':00:00'\n",
    "        else: \n",
    "            result = date[:11]+str(int(date[11:13])+1)+':00:00'\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 매핑용 기상 공항 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dly['time_slot'] = df_dly.sched_datetime.apply(create_time_slot)\n",
    "df_dly['mapping_arp'] = df_dly.origin.map({'포항': '울산', '사천': '여수',\n",
    "                                           '군산': '무안', '원주': '김포',\n",
    "                                           '김해': '울산', '대구': '울산',\n",
    "                                           '청주': '김포', '광주': '무안',\n",
    "                                           '김포': '김포', '무안': '무안',\n",
    "                                           '양양': '양양', '여수': '여수',\n",
    "                                           '울산': '울산', '인천': '인천',\n",
    "                                           '제주': '제주'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dly = pd.merge(df_dly, df_pred, on=['mapping_arp','time_slot'], how='left')\n",
    "df_dly.drop(['mapping_arp','time_slot'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dly.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dly.to_csv('bigcontest/all_merged_test_set.csv',index=False,encoding='CP949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afsnt = pd.read_csv('bigcontest/df_afsnt_total_ver10+weather.csv',engine = 'python', encoding = 'cp949')\n",
    "test = pd.read_csv('bigcontest/all_merged_test_set.csv', engine = 'python', encoding = 'cp949')\n",
    "C10date = ['2017-12-18 00:00:00',\n",
    " '2019-02-15 00:00:00',\n",
    " '2018-11-24 00:00:00',\n",
    " '2018-02-04 00:00:00',\n",
    " '2017-01-20 00:00:00',\n",
    " '2018-01-13 00:00:00',\n",
    " '2018-02-23 00:00:00',\n",
    " '2018-02-06 00:00:00',\n",
    " '2018-01-24 00:00:00',\n",
    " '2018-02-05 00:00:00',\n",
    " '2018-02-08 00:00:00',\n",
    " '2017-02-10 00:00:00',\n",
    " '2018-01-26 00:00:00',\n",
    " '2017-02-22 00:00:00',\n",
    " '2019-01-14 00:00:00',\n",
    " '2017-12-07 00:00:00']\n",
    "df_afsnt= df_afsnt[~((df_afsnt.date.isin(C10date) ==True) & (df_afsnt.cause_delay =='C10'))]\n",
    "df_afsnt = df_afsnt.drop(columns = ['origin_dest','pred_dew'])\n",
    "test = test.drop(columns = ['origin_dest','pred_dew'])\n",
    "# 시간정렬\n",
    "df_afsnt = df_afsnt.sort_values(['year', 'month', 'day'], ascending=[True, True, True])\n",
    "df_afsnt = df_afsnt.reset_index()\n",
    "df_afsnt.drop('index', axis = 1, inplace = True)\n",
    "# 시간정렬\n",
    "testt = test.sort_values(['year', 'month', 'day'], ascending=[True, True, True])\n",
    "test = test.reset_index()\n",
    "test.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "print(__doc__)\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime \n",
    "\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "'''\n",
    "Trainining set과 Validation set의 차이가 77일이고 Validation set의 길이가 15일인 Time Series Cross Validation을 수행합니다.\n",
    "\n",
    "각 Fold의 전체 Validation Set으로 예측한 뒤, Validation Set의 결항 데이터를 제거하여 평가합니다.\n",
    "'''\n",
    "# CV Class\n",
    "class BigconTimeSeriesSplit():\n",
    "    def __init__(self, n_splits):\n",
    "        self.n_splits = n_splits\n",
    "        \n",
    "    def get_n_splits(self, X, y, groups):\n",
    "        return self.n_splits\n",
    "    \n",
    "    def split(self, X, y = None, groups = None):\n",
    "        n_samples = len(X)\n",
    "        k_fold_size = n_samples // self.n_splits\n",
    "        indices = np.arange(n_samples)\n",
    "        \n",
    "        # fold마다 margin을 달리 잡는다.\n",
    "        margin = 1050*77\n",
    "        start = 0\n",
    "        stop = 0 \n",
    "        # 17년 6월, 17년 9월, 18년 6월, 18년 9월, 19년 6월을 val set으로 잡았다.\n",
    "        # fold2와 fold4는 17년 9월15일, 18년 9월 27일이 val set의 시작이다.\n",
    "        mid = [1050*30*6, 1050*30*9 - 1050*3, 1050*30*18, 1050*30*21 + 1050*20, 5 * k_fold_size - 1050*15]\n",
    "        stop = [1050*30*6 + 1050*15, 1050*30*9 + 1050*15 - 1050*3, 1050*30*18 + 1050*15, 1050*30*21 + 1050*15 + 1050*20, 5 * k_fold_size]\n",
    "        for i in range(self.n_splits):\n",
    "            #stop = (i + 1) *  k_fold_size\n",
    "            #mid = stop - 1050*15\n",
    "            yield indices[start:mid[i] - margin], indices[mid[i]: stop[i]]\n",
    "            \n",
    "random_state = 8282\n",
    "bts_cv = BigconTimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 결항데이터 제거용\n",
    "# y_cancel = pd.Series(np.where(df_afsnt_total['is_cancel'] == \"Y\", True, False))\n",
    "# idx_cancel = y_cancel[y_cancel == True].index\n",
    "\n",
    "df_afsnt_total = df_afsnt\n",
    "df_afsnt_total = df_afsnt_total.drop(['month','day','flight','origin','dest','cause_cancel','tailnum','cause_delay','sched_time','real_time',\n",
    "        'is_cancel', 'date','sched_datetime','real_datetime','delay', 'is_regular'], axis=1)\n",
    "\n",
    "# 요일\n",
    "encoded = pd.get_dummies(df_afsnt_total.wday)\n",
    "df_afsnt_total = pd.concat([df_afsnt_total, encoded], axis=1)\n",
    "df_afsnt_total.drop('wday', axis = 1, inplace = True)\n",
    "\n",
    "# 시간범주화\n",
    "encoded = pd.get_dummies(df_afsnt_total.time_discrete)\n",
    "df_afsnt_total = pd.concat([df_afsnt_total, encoded], axis=1)\n",
    "df_afsnt_total.drop('time_discrete', axis = 1, inplace = True)\n",
    "\n",
    "# 항공사\n",
    "encoded = pd.get_dummies(df_afsnt_total.airline)\n",
    "df_afsnt_total = pd.concat([df_afsnt_total, encoded], axis=1)\n",
    "df_afsnt_total.drop('airline', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# is_arrive\n",
    "encoded = pd.get_dummies(df_afsnt_total.is_arrive)\n",
    "df_afsnt_total = pd.concat([df_afsnt_total, encoded], axis=1)\n",
    "df_afsnt_total.drop('is_arrive', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "#origin_dest\n",
    "#encoded = pd.get_dummies(df_afsnt_total.origin_dest)\n",
    "#df_afsnt_total = pd.concat([df_afsnt_total, encoded], axis=1)\n",
    "#df_afsnt_total.drop('origin_dest', axis = 1, inplace = True)\n",
    "\n",
    "clf = lgb.LGBMClassifier(boosting_type= 'dart', colsample_by_tree= 0.6533437523326235, learning_rate= 0.04160534135601695, \n",
    "                              max_depth= 19, n_estimators= 2000, num_leaves= 35, reg_lambda= 0.5508858320081631, class_weight='balanced')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#clf = lgb.LGBMClassifier(max_depth=-1, learning_rate=0.05, objective='binary',\n",
    "#                         random_state=8282, silent=True, metric='None', \n",
    "#                         n_estimators=500, class_weight='balanced',colsample_bytree = 0.9,\n",
    "# min_child_samples = 68,\n",
    "# num_leaves = 100,\n",
    "# subsample = 0.9)\n",
    "\n",
    "y = df_afsnt_total['is_delay'] \n",
    "X = df_afsnt_total.loc[:, df_afsnt_total.columns != 'is_delay']\n",
    "\n",
    "\n",
    "# 요일\n",
    "encoded = pd.get_dummies(test.wday)\n",
    "test = pd.concat([test, encoded], axis=1)\n",
    "test.drop('wday', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# 시간범주화\n",
    "encoded = pd.get_dummies(test.time_discrete)\n",
    "test = pd.concat([test, encoded], axis=1)\n",
    "test.drop('time_discrete', axis = 1, inplace = True)\n",
    "\n",
    "# 항공사\n",
    "encoded = pd.get_dummies(test.airline)\n",
    "test = pd.concat([test, encoded], axis=1)\n",
    "test.drop('airline', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# is_arrive\n",
    "encoded = pd.get_dummies(test.is_arrive)\n",
    "test = pd.concat([test, encoded], axis=1)\n",
    "test.drop('is_arrive', axis = 1, inplace = True)\n",
    "df_test = test.iloc[:, test.columns.isin(X.columns)] \n",
    "\n",
    "print(\"모델을 훈련합니다.\")\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "for fold_num, (train_idx, val_idx) in enumerate(bts_cv.split(X, y), 1):\n",
    "        # Fold의 피팅 시작시간 \n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        X_train, y_train = X.iloc[train_idx, :], y.loc[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx, :], y.loc[val_idx]\n",
    "        \n",
    "        # 훈련\n",
    "        probas_ = pd.DataFrame({'idx_val': val_idx, 'prob': clf.fit(X_train, y_train).predict_proba(X_val)[:, 1]})               \n",
    "        \n",
    "#         # 종속변수의 결항데이터 제거 \n",
    "#         val_idx = list(np.setdiff1d(val_idx, idx_cancel))\n",
    "#         probas_ = probas_[probas_.isin(val_idx)['idx_val']]\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y[val_idx], probas_.iloc[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "                 label='ROC fold %d (AUC = %0.4f)' % (fold_num, roc_auc))\n",
    "        \n",
    "        # Fold의 피팅 소요시간 \n",
    "        time_elapsed = datetime.now() - start_time\n",
    "        print('{0} Fold fitting time (hh:mm:ss.ms) {1}'.format(fold_num, time_elapsed))\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.4f $\\pm$ %0.4f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
